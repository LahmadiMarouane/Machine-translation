{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tmOFPR8VmUq"
      },
      "source": [
        "# Machine translation\n",
        "\n",
        "\n",
        "We will be comparing the performance of three different architectures:\n",
        "* A vanilla RNN\n",
        "* A GRU-RNN\n",
        "* A transformer\n",
        "\n",
        "Do not forget to **select the runtime type as GPU!**\n",
        "\n",
        "**Sources**\n",
        "\n",
        "* Dataset: [Tab-delimited Bilingual Sentence Pairs](http://www.manythings.org/anki/)\n",
        "\n",
        "<!---\n",
        "M. Cettolo, C. Girardi, and M. Federico. 2012. WIT3: Web Inventory of Transcribed and Translated Talks. In Proc. of EAMT, pp. 261-268, Trento, Italy. pdf, bib. [paper](https://aclanthology.org/2012.eamt-1.60.pdf). [website](https://wit3.fbk.eu/2016-01).\n",
        "-->\n",
        "\n",
        "* The code is inspired by this [pytorch tutorial](https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html).\n",
        "\n",
        "*This notebook is quite big, use the table of contents to easily navigate through it.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyCdlapMV8Hu"
      },
      "source": [
        "# Imports and data initializations\n",
        "\n",
        "We first download and parse the dataset. From the parsed sentences\n",
        "we can build the vocabularies and the torch datasets.\n",
        "The end goal of this section is to have an iterator\n",
        "that can yield the pairs of translated datasets, and\n",
        "where each sentences is made of a sequence of tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLbVbH4lu4J0"
      },
      "source": [
        "\n",
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJQfREvFUdoz",
        "outputId": "f78ac06d-88c3-41ff-9336-a3f50f48aba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-11 05:06:56.605538: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-04-11 05:06:56.663712: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-11 05:06:57.689239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-11 05:07:13.464606: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-04-11 05:07:13.521440: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-11 05:07:14.557179: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python3 -m spacy download en > /dev/null\n",
        "!python3 -m spacy download fr > /dev/null\n",
        "!pip install torchinfo > /dev/null\n",
        "!pip install einops > /dev/null\n",
        "!pip install wandb > /dev/null\n",
        "\n",
        "from itertools import takewhile\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator, Vocab\n",
        "from torchtext.datasets import IWSLT2016\n",
        "\n",
        "import einops\n",
        "import wandb\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppPj9CrnsSoW"
      },
      "source": [
        "The tokenizers are objects that are able to divide a python string into a list of tokens (words, punctuations, special tokens...) as a list of strings.\n",
        "\n",
        "The special tokens are used for a particular reasons:\n",
        "* *\\<unk\\>*: Replace an unknown word in the vocabulary by this default token\n",
        "* *\\<pad\\>*: Virtual token used to as padding token so a batch of sentences can have a unique length\n",
        "* *\\<bos\\>*: Token indicating the beggining of a sentence in the target sequence\n",
        "* *\\<eos\\>*: Token indicating the end of a sentence in the target sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxNpMbkvUfGE",
        "outputId": "6a180d3c-11e9-4359-fe53-5785805901a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-11 05:07:42--  http://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7420323 (7.1M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.08M  21.7MB/s    in 0.3s    \n",
            "\n",
            "2023-04-11 05:07:43 (21.7 MB/s) - ‘fra-eng.zip’ saved [7420323/7420323]\n",
            "\n",
            "Archive:  fra-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: fra.txt                 \n",
            "196177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"fr\" could not be loaded, trying \"fr_core_news_sm\" instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Original dataset, but there's a bug on Colab with it\n",
        "# train, valid, _ = IWSLT2016(language_pair=('fr', 'en'))\n",
        "# train, valid = list(train), list(valid)\n",
        "\n",
        "# Another dataset, but it is too huge\n",
        "# !wget https://www.statmt.org/wmt14/training-monolingual-europarl-v7/europarl-v7.en.gz\n",
        "# !wget https://www.statmt.org/wmt14/training-monolingual-europarl-v7/europarl-v7.fr.gz\n",
        "# !gunzip europarl-v7.en.gz\n",
        "# !gunzip europarl-v7.fr.gz\n",
        "\n",
        "# with open('europarl-v7.en', 'r') as my_file:\n",
        "#     english = my_file.readlines()\n",
        "\n",
        "# with open('europarl-v7.fr', 'r') as my_file:\n",
        "#     french = my_file.readlines()\n",
        "\n",
        "# dataset = [\n",
        "#     (en, fr)\n",
        "#     for en, fr in zip(english, french)\n",
        "# ]\n",
        "# print(f'\\n{len(dataset):,} sentences.')\n",
        "\n",
        "# dataset, _ = train_test_split(dataset, test_size=0.8, random_state=0)  # Remove 80% of the dataset (it would be huge otherwise)\n",
        "# train, valid = train_test_split(dataset, test_size=0.2, random_state=0)  # Split between train and validation dataset\n",
        "\n",
        "# Our current dataset\n",
        "!wget http://www.manythings.org/anki/fra-eng.zip\n",
        "!unzip fra-eng.zip\n",
        "\n",
        "\n",
        "df = pd.read_csv('fra.txt', sep='\\t', names=['english', 'french', 'attribution'])\n",
        "train = [\n",
        "    (en, fr) for en, fr in zip(df['english'], df['french'])\n",
        "]\n",
        "train, valid = train_test_split(train, test_size=0.1, random_state=0)\n",
        "print(len(train))\n",
        "\n",
        "en_tokenizer, fr_tokenizer = get_tokenizer('spacy', language='en'), get_tokenizer('spacy', language='fr')\n",
        "\n",
        "SPECIALS = ['<unk>', '<pad>', '<bos>', '<eos>']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ddZvN5FiK9u"
      },
      "source": [
        "## Datasets\n",
        "\n",
        "Functions and classes to build the vocabularies and the torch datasets.\n",
        "The vocabulary is an object able to transform a string token into the id (an int) of that token in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2dKQ6PvZC_U"
      },
      "outputs": [],
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(\n",
        "            self,\n",
        "            dataset: list,\n",
        "            en_vocab: Vocab,\n",
        "            fr_vocab: Vocab,\n",
        "            en_tokenizer,\n",
        "            fr_tokenizer,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dataset = dataset\n",
        "        self.en_vocab = en_vocab\n",
        "        self.fr_vocab = fr_vocab\n",
        "        self.en_tokenizer = en_tokenizer\n",
        "        self.fr_tokenizer = fr_tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the number of examples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index: int) -> tuple:\n",
        "        \"\"\"Return a sample.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "            index: Index of the sample.\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            en_tokens: English tokens of the sample, as a LongTensor.\n",
        "            fr_tokens: French tokens of the sample, as a LongTensor.\n",
        "        \"\"\"\n",
        "        # Get the strings\n",
        "        en_sentence, fr_sentence = self.dataset[index]\n",
        "\n",
        "        # To list of words\n",
        "        # We also add the beggining-of-sentence and end-of-sentence tokens\n",
        "        en_tokens = ['<bos>'] + self.en_tokenizer(en_sentence) + ['<eos>']\n",
        "        fr_tokens = ['<bos>'] + self.fr_tokenizer(fr_sentence) + ['<eos>']\n",
        "\n",
        "        # To list of tokens\n",
        "        en_tokens = self.en_vocab(en_tokens)  # list[int]\n",
        "        fr_tokens = self.fr_vocab(fr_tokens)\n",
        "\n",
        "        return torch.LongTensor(en_tokens), torch.LongTensor(fr_tokens)\n",
        "\n",
        "\n",
        "def yield_tokens(dataset, tokenizer, lang):\n",
        "    \"\"\"Tokenize the whole dataset and yield the tokens.\n",
        "    \"\"\"\n",
        "    assert lang in ('en', 'fr')\n",
        "    sentence_idx = 0 if lang == 'en' else 1\n",
        "\n",
        "    for sentences in dataset:\n",
        "        sentence = sentences[sentence_idx]\n",
        "        tokens = tokenizer(sentence)\n",
        "        yield tokens\n",
        "\n",
        "\n",
        "def build_vocab(dataset: list, en_tokenizer, fr_tokenizer, min_freq: int):\n",
        "    \"\"\"Return two vocabularies, one for each language.\n",
        "    \"\"\"\n",
        "    en_vocab = build_vocab_from_iterator(\n",
        "        yield_tokens(dataset, en_tokenizer, 'en'),\n",
        "        min_freq=min_freq,\n",
        "        specials=SPECIALS,\n",
        "    )\n",
        "    en_vocab.set_default_index(en_vocab['<unk>'])  # Default token for unknown words\n",
        "\n",
        "    fr_vocab = build_vocab_from_iterator(\n",
        "        yield_tokens(dataset, fr_tokenizer, 'fr'),\n",
        "        min_freq=min_freq,\n",
        "        specials=SPECIALS,\n",
        "    )\n",
        "    fr_vocab.set_default_index(fr_vocab['<unk>'])\n",
        "\n",
        "    return en_vocab, fr_vocab\n",
        "\n",
        "\n",
        "def preprocess(\n",
        "        dataset: list,\n",
        "        en_tokenizer,\n",
        "        fr_tokenizer,\n",
        "        max_words: int,\n",
        "    ) -> list:\n",
        "    \"\"\"Preprocess the dataset.\n",
        "    Remove samples where at least one of the sentences are too long.\n",
        "    Those samples takes too much memory.\n",
        "    Also remove the pending '\\n' at the end of sentences.\n",
        "    \"\"\"\n",
        "    filtered = []\n",
        "\n",
        "    for en_s, fr_s in dataset:\n",
        "        if len(en_tokenizer(en_s)) >= max_words or len(fr_tokenizer(fr_s)) >= max_words:\n",
        "            continue\n",
        "\n",
        "        en_s = en_s.replace('\\n', '')\n",
        "        fr_s = fr_s.replace('\\n', '')\n",
        "\n",
        "        filtered.append((en_s, fr_s))\n",
        "\n",
        "    return filtered\n",
        "\n",
        "\n",
        "def build_datasets(\n",
        "        max_sequence_length: int,\n",
        "        min_token_freq: int,\n",
        "        en_tokenizer,\n",
        "        fr_tokenizer,\n",
        "        train: list,\n",
        "        val: list,\n",
        "    ) -> tuple:\n",
        "    \"\"\"Build the training, validation and testing datasets.\n",
        "    It takes care of the vocabulary creation.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        - max_sequence_length: Maximum number of tokens in each sequences.\n",
        "            Having big sequences increases dramatically the VRAM taken during training.\n",
        "        - min_token_freq: Minimum number of occurences each token must have\n",
        "            to be saved in the vocabulary. Reducing this number increases\n",
        "            the vocabularies's size.\n",
        "        - en_tokenizer: Tokenizer for the english sentences.\n",
        "        - fr_tokenizer: Tokenizer for the french sentences.\n",
        "        - train and val: List containing the pairs (english, french) sentences.\n",
        "\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        - (train_dataset, val_dataset): Tuple of the two TranslationDataset objects.\n",
        "    \"\"\"\n",
        "    datasets = [\n",
        "        preprocess(samples, en_tokenizer, fr_tokenizer, max_sequence_length)\n",
        "        for samples in [train, val]\n",
        "    ]\n",
        "\n",
        "    en_vocab, fr_vocab = build_vocab(datasets[0], en_tokenizer, fr_tokenizer, min_token_freq)\n",
        "\n",
        "    datasets = [\n",
        "        TranslationDataset(samples, en_vocab, fr_vocab, en_tokenizer, fr_tokenizer)\n",
        "        for samples in datasets\n",
        "    ]\n",
        "\n",
        "    return datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWlH-qEbkoYA"
      },
      "outputs": [],
      "source": [
        "def generate_batch(data_batch: list, src_pad_idx: int, tgt_pad_idx: int) -> tuple:\n",
        "    \"\"\"Add padding to the given batch so that all\n",
        "    the samples are of the same size.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        data_batch: List of samples.\n",
        "            Each sample is a tuple of LongTensors of varying size.\n",
        "        src_pad_idx: Source padding index value.\n",
        "        tgt_pad_idx: Target padding index value.\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        en_batch: Batch of tokens for the padded english sentences.\n",
        "            Shape of [batch_size, max_en_len].\n",
        "        fr_batch: Batch of tokens for the padded french sentences.\n",
        "            Shape of [batch_size, max_fr_len].\n",
        "    \"\"\"\n",
        "    en_batch, fr_batch = [], []\n",
        "    for en_tokens, fr_tokens in data_batch:\n",
        "        en_batch.append(en_tokens)\n",
        "        fr_batch.append(fr_tokens)\n",
        "\n",
        "    en_batch = pad_sequence(en_batch, padding_value=src_pad_idx, batch_first=True)\n",
        "    fr_batch = pad_sequence(fr_batch, padding_value=tgt_pad_idx, batch_first=True)\n",
        "    return en_batch, fr_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8Gs4Myjh-jV"
      },
      "source": [
        "# Models architecture\n",
        "This is where you have to code the architectures.\n",
        "\n",
        "In a machine translation task, the model takes as input the whole\n",
        "source sentence along with the current known tokens of the target,\n",
        "and predict the next token in the target sequence.\n",
        "This means that the target tokens are predicted in an autoregressive\n",
        "manner, starting from the first token (right after the *\\<bos\\>* token) and producing tokens one by one until the last *\\<eos\\>* token.\n",
        "\n",
        "Formally, we define $s = [s_1, ..., s_{N_s}]$ as the source sequence made of $N_s$ tokens.\n",
        "We also define $t^i = [t_1, ..., t_i]$ as the target sequence at the beginning of the step $i$.\n",
        "\n",
        "The output of the model parameterized by $\\theta$ is:\n",
        "\n",
        "$$\n",
        "T_{i+1} = p(t_{i+1} | s, t^i ; \\theta )\n",
        "$$\n",
        "\n",
        "Where $T_{i+1}$ is the distribution of the next token $t_{i+1}$.\n",
        "\n",
        "The loss is simply a *cross entropy loss* over the whole steps, where each class is a token of the vocabulary.\n",
        "\n",
        "![RNN schema for machinea translation](https://www.simplilearn.com/ice9/free_resources_article_thumb/machine-translation-model-with-encoder-decoder-rnn.jpg)\n",
        "\n",
        "Note that in this image the english sentence is provided in reverse.\n",
        "\n",
        "---\n",
        "\n",
        "In pytorch, there is no dinstinction between an intermediate layer or a whole model having multiple layers in itself.\n",
        "Every layers or models inherit from the `torch.nn.Module`.\n",
        "This module needs to define the `__init__` method where you instanciate the layers,\n",
        "and the `forward` method where you decide how the inputs and the layers of the module interact between them.\n",
        "Thanks to the autograd computations of pytorch, you do not have\n",
        "to implement any backward method!\n",
        "\n",
        "A really important advice is to **always look at\n",
        "the shape of your input and your output.**\n",
        "From that, you can often guess how the layers should interact\n",
        "with the inputs to produce the right output.\n",
        "You can also easily detect if there's something wrong going on.\n",
        "\n",
        "You are more than advised to use the `einops` library and the `torch.einsum` function. This will require less operations than 'classical' code, but note that it's a bit trickier to use.\n",
        "This is a way of describing tensors manipulation with strings, bypassing the multiple tensor methods executed in the background.\n",
        "You can find a nice presentation of `einops` [here](https://einops.rocks/1-einops-basics/).\n",
        "A paper has just been released about einops [here](https://paperswithcode.com/paper/einops-clear-and-reliable-tensor).\n",
        "\n",
        "**A great tutorial on pytorch can be found [here](https://stanford.edu/class/cs224n/materials/CS224N_PyTorch_Tutorial.html).**\n",
        "Spending 3 hours on this tutorial is *no* waste of time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xodRThXg2DHM"
      },
      "source": [
        "## RNN models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvfRVUKm1u8e"
      },
      "source": [
        "### RNN\n",
        "Here you have to implement a recurrent neural network. You will need to create a single RNN Layer, and a module allowing to stack these layers. Look up the pytorch documentation to figure out this module's operations and what is communicated from one layer to another.\n",
        "\n",
        "The `RNNCell` layer produce one hidden state vector for each sentence in the batch\n",
        "(useful for the output of the encoder), and also produce one embedding for each\n",
        "token in each sentence (useful for the output of the decoder).\n",
        "\n",
        "The `RNN` module is composed of a stack of `RNNCell`. Each token embeddings\n",
        "coming out from a previous `RNNCell` is used as an input for the next `RNNCell` layer.\n",
        "\n",
        "**Be careful !** Our `RNNCell` implementation is not exactly the same thing as\n",
        "the PyTorch's `nn.RNNCell`. PyTorch implements only the operations for one token\n",
        "(so you would need to loop through each tokens inside the `RNN` instead).\n",
        "You are free to implement `RNN` and `RNNCell` the way you want, as long as it has the expected behaviour of a RNN.\n",
        "\n",
        "The same thing apply for the `GRU` and `GRUCell`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RNNCell(nn.Module):\n",
        "    \"\"\"A single RNN layer.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        input_size: Size of each input token.\n",
        "        hidden_size: Size of each RNN hidden state.\n",
        "        dropout: Dropout rate.\n",
        "\n",
        "    Important note: This layer does not exactly the same thing as nn.RNNCell does.\n",
        "    PyTorch implementation is only doing one simple pass over one token for each batch.\n",
        "    This implementation is taking the whole sequence of each batch and provide the\n",
        "    final hidden state along with the embeddings of each token in each sequence.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_size: int,\n",
        "            hidden_size: int,\n",
        "            dropout: float,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.Wih = nn.Linear(input_size, hidden_size)\n",
        "        self.Whh = nn.Linear(hidden_size, hidden_size)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.device = config[\"device\"]\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.FloatTensor, h: torch.FloatTensor) -> tuple:\n",
        "        \"\"\"Go through all the sequence in x, iteratively updating\n",
        "        the hidden state h.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "            x: Input sequence.\n",
        "                Shape of [batch_size, seq_len, input_size].\n",
        "            h: Initial hidden state.\n",
        "                Shape of [batch_size, hidden_size].\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            y: Token embeddings.\n",
        "                Shape of [batch_size, seq_len, hidden_size].\n",
        "            h: Last hidden state.\n",
        "                Shape of [batch_size, hidden_size].\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        y = torch.empty(batch_size, seq_len, self.hidden_size).to(self.device)\n",
        "        for i in range(seq_len):\n",
        "            ih = self.Wih(x[:, i])\n",
        "            h = self.Whh(h)\n",
        "            h = self.tanh(h + ih)\n",
        "            y[:, i] = h\n",
        "\n",
        "        h = self.dropout(h)\n",
        "        y = self.dropout(y)\n",
        "        return y, h\n",
        "\n",
        "\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    \"\"\"Implementation of an RNN based\n",
        "    on https://pytorch.org/docs/stable/generated/torch.nn.RNN.html.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        input_size: Size of each input token.\n",
        "        hidden_size: Size of each RNN hidden state.\n",
        "        num_layers: Number of layers (RNNCell or GRUCell).\n",
        "        dropout: Dropout rate.\n",
        "        model_type: Either 'RNN' or 'GRU', to select which model we want.\n",
        "            This parameter can be removed if you decide to use the module GRU.\n",
        "            Indeed, GRU should have exactly the same code as this module,\n",
        "            but with GRUCell instead of RNNCell. We let the freedom for you\n",
        "            to decide at which level you want to specialise the modules (either\n",
        "            in TranslationRNN by creating a GRU or a RNN, or in RNN\n",
        "            by creating a GRUCell or a RNNCell).\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_size: int,\n",
        "            hidden_size: int,\n",
        "            num_layers: int,\n",
        "            dropout: float,\n",
        "            model_type: str,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.device = config[\"device\"]\n",
        "\n",
        "\n",
        "        self.model = nn.ModuleList([\n",
        "            RNNCell(\n",
        "                input_size if l == 0 else hidden_size,\n",
        "                hidden_size,\n",
        "                dropout if l != num_layers - 1 else 0\n",
        "            ) if model_type == 'RNN' else\n",
        "            GRUCell(\n",
        "                input_size if l == 0 else hidden_size,\n",
        "                hidden_size,\n",
        "                dropout if l != num_layers - 1 else 0\n",
        "            ) for l in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x: torch.FloatTensor, h: torch.FloatTensor=None) -> tuple:\n",
        "        \"\"\"Pass the input sequence through all the RNN cells.\n",
        "        Returns the output and the final hidden state of each RNN layer\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "            x: Input sequence.\n",
        "                Shape of [batch_size, seq_len, input_size].\n",
        "            h: Hidden state for each RNN layer.\n",
        "                Can be None, in which case an initial hidden state is created.\n",
        "                Shape of [batch_size, n_layers, hidden_size].\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            y: Output embeddings for each token after the RNN layers.\n",
        "                Shape of [batch_size, seq_len, hidden_size].\n",
        "            h: Final hidden state.\n",
        "                Shape of [batch_size, n_layers, hidden_size].\n",
        "        \"\"\"\n",
        "        batch_size,_,_ = x.size()\n",
        "        output_emb = x\n",
        "        final_hidden_state = torch.empty(batch_size, self.num_layers, self.hidden_size).to(self.device)\n",
        "\n",
        "        if h == None:\n",
        "            h = torch.zeros(batch_size, self.num_layers, self.hidden_size).to(self.device)\n",
        "\n",
        "        for i, Rnncell in enumerate(self.model):\n",
        "            hh = h[:, i]\n",
        "            output_emb, hh = Rnncell(output_emb, hh)\n",
        "\n",
        "            final_hidden_state[:, i] = hh\n",
        "        return output_emb, final_hidden_state"
      ],
      "metadata": {
        "id": "T7aat8o9QGcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0ciaamtvK0R"
      },
      "source": [
        "### GRU\n",
        "Here you have to implement a GRU-RNN. This architecture is close to the Vanilla RNN but perform different operations. Look up the pytorch documentation to figure out the differences."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_size: int,\n",
        "            hidden_size: int,\n",
        "            num_layers: int,\n",
        "            dropout: float,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.h_size = hidden_size\n",
        "        self.n_layers = num_layers\n",
        "        self.device = config[\"device\"]\n",
        "\n",
        "        # Create GRU layers\n",
        "        self.gru_layers = nn.ModuleList([GRUCell(\n",
        "            input_size if n == 0 else hidden_size,\n",
        "            hidden_size,\n",
        "            dropout if n != (num_layers-1) else 0) for n in range(num_layers)])\n",
        "\n",
        "    def forward(self, x: torch.FloatTensor, h: torch.FloatTensor=None) -> tuple:\n",
        "        batch_size, _, _ = x.size()\n",
        "\n",
        "        out_seq = x\n",
        "\n",
        "        final_h = torch.empty(batch_size, self.n_layers, self.h_size).to(self.device)\n",
        "\n",
        "        if h == None:\n",
        "            h = torch.zeros(batch_size, self.n_layers, self.h_size).to(self.device)\n",
        "\n",
        "        for i, cell in enumerate(self.gru_layers):\n",
        "            h_layer = h[:, i]\n",
        "            out_seq, h_layer = cell(out_seq, h_layer)\n",
        "            final_h[:, i] = h_layer\n",
        "        return out_seq, final_h\n",
        "\n",
        "\n",
        "class GRUCell(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_size: int,\n",
        "            hidden_size: int,\n",
        "            dropout: float,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.gate_size = 3\n",
        "\n",
        "        # Define the weights for the input and hidden states\n",
        "        self.W_input = nn.Linear(input_size, hidden_size * self.gate_size)\n",
        "        self.W_hidden = nn.Linear(hidden_size, hidden_size * self.gate_size)\n",
        "\n",
        "        self.device = config[\"device\"]\n",
        "        self.h_size = hidden_size\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "\n",
        "        std = 1.0 / np.sqrt(self.h_size)\n",
        "\n",
        "        # Initialize the weights\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-std, std)\n",
        "\n",
        "    def forward(self, x: torch.FloatTensor, h: torch.FloatTensor) -> tuple:\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        out_emb = torch.empty(batch_size, seq_len, self.h_size).to(self.device)\n",
        "\n",
        "        final_h = h\n",
        "\n",
        "        for token in range(seq_len):\n",
        "            x_gate = self.W_input(x[:, token])\n",
        "            h_gate = self.W_hidden(final_h)\n",
        "\n",
        "            # Split input and hidden states into gates\n",
        "            i_r, i_u, i_n = x_gate.chunk(self.gate_size, 1)\n",
        "            h_r, h_u, h_n = h_gate.chunk(self.gate_size, 1)\n",
        "\n",
        "            # Compute gate activations\n",
        "            reset_gate = torch.sigmoid(i_r + h_r)\n",
        "            update_gate = torch.sigmoid(i_u + h_u)\n",
        "            new_candidate_state = torch.tanh(i_n + (reset_gate * h_n))\n",
        "\n",
        "            final_h = update_gate * final_h + (1 - update_gate) * new_candidate_state\n",
        "\n",
        "            out_emb[:, token] = final_h\n",
        "\n",
        "        out_emb = self.dropout_layer(out_emb)\n",
        "        final_h = self.dropout_layer(final_h)\n",
        "\n",
        "        return out_emb, final_h"
      ],
      "metadata": {
        "id": "LohOqhd5QmUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boIetZUy1f-5"
      },
      "source": [
        "### Translation RNN\n",
        "\n",
        "This module instanciates a vanilla RNN or a GRU-RNN and performs the translation task. You have to:\n",
        "* Encode the source and target sequence\n",
        "* Pass the final hidden state of the encoder to the decoder (one for each layer)\n",
        "* Decode the hidden state into the target sequence\n",
        "\n",
        "We use teacher forcing for training, meaning that when the next token is predicted, that prediction is based on the previous true target tokens."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TranslationRNN(nn.Module):\n",
        "    \"\"\"Basic RNN encoder and decoder for a translation task.\n",
        "    It can run as a vanilla RNN or a GRU-RNN.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        n_tokens_src: Number of tokens in the source vocabulary.\n",
        "        n_tokens_tgt: Number of tokens in the target vocabulary.\n",
        "        dim_embedding: Dimension size of the word embeddings (for both language).\n",
        "        dim_hidden: Dimension size of the hidden layers in the RNNs\n",
        "            (for both the encoder and the decoder).\n",
        "        n_layers: Number of layers in the RNNs.\n",
        "        dropout: Dropout rate.\n",
        "        src_pad_idx: Source padding index value.\n",
        "        tgt_pad_idx: Target padding index value.\n",
        "        model_type: Either 'RNN' or 'GRU', to select which model we want.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            n_tokens_src: int,\n",
        "            n_tokens_tgt: int,\n",
        "            dim_embedding: int,\n",
        "            dim_hidden: int,\n",
        "            n_layers: int,\n",
        "            dropout: float,\n",
        "            src_pad_idx: int,\n",
        "            tgt_pad_idx: int,\n",
        "            model_type: str,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO\n",
        "        self.device = config['device']\n",
        "        self.dim_hidden = dim_hidden\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.embedding_src = nn.Embedding(num_embeddings=n_tokens_src, embedding_dim=dim_embedding, padding_idx=src_pad_idx)\n",
        "        self.embedding_tgt = nn.Embedding(num_embeddings=n_tokens_tgt, embedding_dim=dim_embedding, padding_idx=tgt_pad_idx)\n",
        "\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "\n",
        "        if model_type == 'RNN':\n",
        "            self.encoder = RNN(input_size=dim_embedding,\n",
        "                            hidden_size=dim_hidden,\n",
        "                            num_layers=n_layers,\n",
        "                            dropout=dropout,\n",
        "                            model_type=model_type)\n",
        "            self.decoder = RNN(input_size=dim_embedding,\n",
        "                            hidden_size=dim_hidden,\n",
        "                            num_layers=n_layers,\n",
        "                            dropout=dropout,\n",
        "                            model_type=model_type)\n",
        "\n",
        "        elif model_type == 'GRU':\n",
        "            self.encoder = GRU(input_size=dim_embedding,\n",
        "                            hidden_size=dim_hidden,\n",
        "                            num_layers=n_layers,\n",
        "                            dropout=dropout)\n",
        "            self.decoder = GRU(input_size=dim_embedding,\n",
        "                            hidden_size=dim_hidden,\n",
        "                            num_layers=n_layers,\n",
        "                            dropout=dropout)\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(dim_hidden)\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim_hidden, 128),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.Linear(128, n_tokens_tgt)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        source: torch.LongTensor,\n",
        "        target: torch.LongTensor\n",
        "    ) -> torch.FloatTensor:\n",
        "        \"\"\"Predict the target tokens logites based on the source tokens.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "            source: Batch of source sentences.\n",
        "                Shape of [batch_size, src_seq_len].\n",
        "            target: Batch of target sentences.\n",
        "                Shape of [batch_size, tgt_seq_len].\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            y: Distributions over the next token for all tokens in each sentences.\n",
        "                Those need to be the logits only, do not apply a softmax because\n",
        "                it will be done in the loss computation for numerical stability.\n",
        "                See https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html for more informations.\n",
        "                Shape of [batch_size, tgt_seq_len, n_tokens_tgt].\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        x_source = self.embedding_src(source)\n",
        "        _, h_enc = self.encoder(x_source)\n",
        "        x_target = self.embedding_tgt(target)\n",
        "        h_enc = self.layer_norm(h_enc)\n",
        "        x_dec, _ = self.decoder(x_target, h_enc)\n",
        "        y = self.mlp(x_dec)\n",
        "\n",
        "        return y"
      ],
      "metadata": {
        "id": "XUl3z4g2Rs48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZcGlRnZvOnY"
      },
      "source": [
        "## Transformer model\n",
        "Here you have to code the Transformer architecture.\n",
        "It is divided in three parts:\n",
        "* Attention layers\n",
        "* Encoder and decoder layers\n",
        "* Main layers (gather the encoder and decoder layers)\n",
        "\n",
        "The [illustrated transformer](https://jalammar.github.io/illustrated-transformer/) blog can help you\n",
        "understanding how the architecture works.\n",
        "Once this is done, you can use [the annontated transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html) to have an idea of how to code this architecture.\n",
        "We encourage you to use `torch.einsum` and the `einops` library as much as you can. It will make your code simpler.\n",
        "\n",
        "---\n",
        "**Implementation order**\n",
        "\n",
        "To help you with the implementation, we advise you following this order:\n",
        "* Implement `TranslationTransformer` and use `nn.Transformer` instead of `Transformer`\n",
        "* Implement `Transformer` and use `nn.TransformerDecoder` and `nn.TransformerEnocder`\n",
        "* Implement the `TransformerDecoder` and `TransformerEncoder` and use `nn.MultiHeadAttention`\n",
        "* Implement `MultiHeadAttention`\n",
        "\n",
        "Do not forget to add `batch_first=True` when necessary in the `nn` modules."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFxV-6M3402p"
      },
      "source": [
        "### Attention layers\n",
        "We use a `MultiHeadAttention` module, that is able to perform self-attention aswell as cross-attention (depending on what you give as queries, keys and values).\n",
        "\n",
        "**Attention**\n",
        "\n",
        "\n",
        "It takes the multiheaded queries, keys and values as input.\n",
        "It computes the attention between the queries and the keys and return the attended values.\n",
        "\n",
        "The implementation of this function can greatly be improved with *einsums*.\n",
        "\n",
        "**MultiheadAttention**\n",
        "\n",
        "Computes the multihead queries, keys and values and feed them to the `attention` function.\n",
        "You also need to merge the key padding mask and the attention mask into one mask.\n",
        "\n",
        "The implementation of this module can greatly be improved with *einops.rearrange*."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "import math\n",
        "def attention(\n",
        "        q: torch.FloatTensor,\n",
        "        k: torch.FloatTensor,\n",
        "        v: torch.FloatTensor,\n",
        "        mask: torch.BoolTensor=None,\n",
        "        dropout: nn.Dropout=None,\n",
        "    ) -> tuple:\n",
        "    \"\"\"\n",
        "    Computes multihead scaled dot-product attention from the\n",
        "    projected queries, keys and values.\n",
        "\n",
        "    Args:\n",
        "        q: Batch of queries.\n",
        "            Shape of [batch_size, seq_len_1, n_heads, dim_model].\n",
        "        k: Batch of keys.\n",
        "            Shape of [batch_size, seq_len_2, n_heads, dim_model].\n",
        "        v: Batch of values.\n",
        "            Shape of [batch_size, seq_len_2, n_heads, dim_model].\n",
        "        mask: Prevent tokens to attend to some other tokens (for padding or autoregressive attention).\n",
        "            Attention is prevented where the mask is True.\n",
        "            Shape of [batch_size, 1, seq_len_1, seq_len_2],\n",
        "            or broadcastable to that shape.\n",
        "        dropout: Dropout layer to use.\n",
        "\n",
        "    Returns:\n",
        "        y: Multihead scaled dot-attention between the queries, keys and values.\n",
        "            Shape of [batch_size, seq_len_1, n_heads, dim_model].\n",
        "        attn: Computed attention between the keys and the queries.\n",
        "            Shape of [batch_size, n_heads, seq_len_1, seq_len_2].\n",
        "    \"\"\"\n",
        "    # Calculate the dot-product of q and k for each head\n",
        "    # Shape of [batch_size, n_heads, seq_len_1, seq_len_2]\n",
        "    #scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(q.size(-1))\n",
        "    scores = torch.einsum(\"bqhd,bkhd->bhqk\", [q, k]) / (d_k ** 0.5)\n",
        "    # Apply mask to the score#\n",
        "    print('q',q.shape)\n",
        "    print('k',k.shape)\n",
        "    print('score',scores.shape)\n",
        "    print('mask',mask.shape)\n",
        "    print(q.size(1))\n",
        "    #mask = mask.expand(-1, q.size(1), -1, -1, -1)\n",
        "    mask = mask.expand(q.size(0), 1, q.size(1), v.size(1))\n",
        "    print('mask',mask.shape)\n",
        "    scores.masked_fill_(mask, -1e9)\n",
        "\n",
        "    # Apply softmax to the score\n",
        "    # Shape of [batch_size, n_heads, seq_len_1, seq_len_2]\n",
        "    attn_weights = nn.softmax(scores, dim=-1)\n",
        "\n",
        "    # Apply dropout\n",
        "    if dropout is not None:\n",
        "        attn_weights = dropout(attn_weights)\n",
        "\n",
        "    # Calculate the weighted sum of values\n",
        "    # Shape of [batch_size, seq_len_1, n_heads, dim_model]\n",
        "    y = torch.matmul(attn_weights, v)\n",
        "\n",
        "    # Transpose the dimensions for compatibility with nn.MultiheadAttention\n",
        "    # Shape of [batch_size, seq_len_1, n_heads, dim_model]\n",
        "    y = y.transpose(1, 2)\n",
        "\n",
        "    # Transpose the attention weights dimensions\n",
        "    # Shape of [batch_size, n_heads, seq_len_1, seq_len_2]\n",
        "    attn_weights = attn_weights.transpose(1, 2)\n",
        "\n",
        "    return y, attn_weights\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "    def __init__(self, dim, n_heads, dropout):\n",
        "        super().__init__()\n",
        "        assert dim % n_heads == 0\n",
        "\n",
        "        self.dim = dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = dim // n_heads\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.q_proj = nn.Linear(dim, dim)\n",
        "        self.k_proj = nn.Linear(dim, dim)\n",
        "        self.v_proj = nn.Linear(dim, dim)\n",
        "        self.out_proj = nn.Linear(dim, dim)\n",
        "\n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, q, k, v, key_padding_mask=None, attn_mask=None):\n",
        "        batch_size, seq_len_1, dim_model = q.size()\n",
        "        seq_len_2 = k.size(1)\n",
        "\n",
        "        q = self.q_proj(q).view(batch_size, seq_len_1, self.n_heads, self.head_dim)\n",
        "        k = self.k_proj(k).view(batch_size, seq_len_2, self.n_heads, self.head_dim)\n",
        "        v = self.v_proj(v).view(batch_size, seq_len_2, self.n_heads, self.head_dim)\n",
        "\n",
        "        q = q.transpose(1, 2)\n",
        "        k = k.transpose(1, 2)\n",
        "        v = v.transpose(1, 2)\n",
        "\n",
        "        if attn_mask is not None:\n",
        "            attn_mask = attn_mask.unsqueeze(0).unsqueeze(1)\n",
        "\n",
        "        if key_padding_mask is not None:\n",
        "            key_padding_mask = key_padding_mask.unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        if attn_mask is None:\n",
        "            mask = key_padding_mask\n",
        "        else:\n",
        "            mask = attn_mask if key_padding_mask is None else (key_padding_mask | attn_mask)\n",
        "\n",
        "        attn_weights = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "        if mask is not None:\n",
        "            attn_weights = attn_weights.masked_fill(mask, float(\"-inf\"))\n",
        "\n",
        "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
        "        attn_weights = self.dropout_layer(attn_weights)\n",
        "\n",
        "        y = torch.matmul(attn_weights, v)\n",
        "        y = y.transpose(1, 2).contiguous().view(batch_size, seq_len_1, dim_model)\n",
        "        y = self.out_proj(y)\n",
        "\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "K4oYFZKz0ulw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0jOZxOwu_Uj"
      },
      "outputs": [],
      "source": [
        "from numpy.core.fromnumeric import shape\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "def attention(\n",
        "    q: torch.FloatTensor,\n",
        "    k: torch.FloatTensor,\n",
        "    v: torch.FloatTensor,\n",
        "    mask: torch.BoolTensor = None,\n",
        "    dropout: nn.Dropout = None,\n",
        ") -> tuple:\n",
        "\n",
        "    d_k = q.size(-1)\n",
        "    print(\"q\",q.shape)\n",
        "    print(\"k\",k.shape)\n",
        "    print(\"v\",v.shape)\n",
        "    scores = torch.einsum(\"bqhd,bkhd->bhqk\", [q, k]) / (d_k ** 0.5)\n",
        "    print(\"scores\",scores.shape)\n",
        "    if mask is not None:\n",
        "        print(\"mask\",mask.shape)\n",
        "        mask = mask.unsqueeze(1).unsqueeze(2).unsqueeze(2).expand(-1, 4, 180, 180)\n",
        "        print(\"mask1\",mask.shape)\n",
        "        scores = scores.masked_fill(mask, float(\"-inf\"))\n",
        "\n",
        "    attn = torch.softmax(scores, dim=-1)\n",
        "\n",
        "    if dropout is not None:\n",
        "        attn = dropout(attn)\n",
        "\n",
        "    y = torch.einsum(\"bhqk,bkhd->bqhd\", [attn, v])\n",
        "\n",
        "    return y, attn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            dim: int,\n",
        "            n_heads: int,\n",
        "            dropout: float,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        assert dim % n_heads == 0\n",
        "\n",
        "        self.dim = dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = dim // n_heads\n",
        "\n",
        "        self.qkv_proj = nn.Linear(dim, dim * 3, bias=False)\n",
        "        self.out_proj = nn.Linear(dim, dim, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.rearrange_qkv = Rearrange(\"b s (h d qkv) -> qkv b s h d\", h=n_heads, qkv=3)\n",
        "        self.rearrange_out = Rearrange(\"b s h d -> b s (h d)\")\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            q: torch.FloatTensor,\n",
        "            k: torch.FloatTensor,\n",
        "            v: torch.FloatTensor,\n",
        "            key_padding_mask: torch.BoolTensor = None,\n",
        "            attn_mask: torch.BoolTensor = None,\n",
        "        ) -> torch.FloatTensor:\n",
        "\n",
        "        b, _, _ = q.size()\n",
        "\n",
        "        qkv = self.qkv_proj(torch.cat([q, k, v], dim=1))\n",
        "        q, k, v = self.rearrange_qkv(qkv).unbind(0)\n",
        "        if key_padding_mask is not None:\n",
        "            key_padding_mask = key_padding_mask.unsqueeze(1).unsqueeze(2)\n",
        "            print(\"key_padding_mask size after unsqueeze:\", key_padding_mask.size())\n",
        "\n",
        "\n",
        "        if attn_mask is not None:\n",
        "            attn_mask = attn_mask.unsqueeze(0).unsqueeze(1)\n",
        "\n",
        "\n",
        "        if attn_mask is None:\n",
        "            mask = key_padding_mask\n",
        "        else:\n",
        "            key_padding_mask_broadcasted = key_padding_mask.expand(-1, -1, attn_mask.size(2), -1)\n",
        "            mask = key_padding_mask_broadcasted | attn_mask\n",
        "\n",
        "        y, _ = attention(q, k, v, mask, self.dropout)\n",
        "\n",
        "        y = self.rearrange_out(y)\n",
        "        y = self.out_proj(y)\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIpHjOtK47DH"
      },
      "source": [
        "### Encoder and decoder layers\n",
        "\n",
        "**TranformerEncoder**\n",
        "\n",
        "Apply self-attention layers onto the source tokens.\n",
        "It only needs the source key padding mask.\n",
        "\n",
        "\n",
        "**TranformerDecoder**\n",
        "\n",
        "Apply masked self-attention layers to the target tokens and cross-attention\n",
        "layers between the source and the target tokens.\n",
        "It needs the source and target key padding masks, and the target attention mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d-ukpIOu_RH"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model: int, d_ff: int, nhead: int, dropout: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn = MultiheadAttention(d_model, nhead, dropout)\n",
        "        self.cross_attn = MultiheadAttention(d_model, nhead, dropout)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, src, tgt, tgt_mask_attn, src_key_padding_mask, tgt_key_padding_mask):\n",
        "        attn_output = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask_attn, key_padding_mask=tgt_key_padding_mask)\n",
        "        tgt = self.norm1(tgt + attn_output)\n",
        "        attn_output = self.cross_attn(tgt, src, src, key_padding_mask=src_key_padding_mask)\n",
        "        tgt = self.norm2(tgt + attn_output)\n",
        "        ffn_output = self.ffn(tgt)\n",
        "        tgt = self.norm3(tgt + ffn_output)\n",
        "\n",
        "        return tgt\n",
        "\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, d_model: int, d_ff: int, num_decoder_layer: int, nhead: int, dropout: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([TransformerDecoderLayer(d_model, d_ff, nhead, dropout) for _ in range(num_decoder_layer)])\n",
        "\n",
        "    def forward(self, src, tgt, tgt_mask_attn, src_key_padding_mask, tgt_key_padding_mask):\n",
        "        for layer in self.layers:\n",
        "            tgt = layer(src, tgt, tgt_mask_attn, src_key_padding_mask, tgt_key_padding_mask)\n",
        "\n",
        "        return tgt\n",
        "\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model: int, d_ff: int, nhead: int, dropout: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn = MultiheadAttention(d_model, nhead, dropout)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, src, key_padding_mask):\n",
        "        attn_output = self.self_attn(src, src, src, key_padding_mask=key_padding_mask)\n",
        "        src = self.norm1(src + attn_output)\n",
        "        ffn_output = self.ffn(src)\n",
        "        src = self.norm2(src + ffn_output)\n",
        "\n",
        "        return src\n",
        "\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, d_model: int, dim_feedforward: int, num_encoder_layers: int, nheads: int, dropout: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([TransformerEncoderLayer(d_model, dim_feedforward, nheads, dropout) for _ in range(num_encoder_layers)])\n",
        "\n",
        "    def forward(self, src, key_padding_mask):\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, key_padding_mask)\n",
        "\n",
        "        return src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd3kGoRO4_TV"
      },
      "source": [
        "### Main layers\n",
        "This section gather the `Transformer` and the `TranslationTransformer` modules.\n",
        "\n",
        "**Transformer**\n",
        "\n",
        "\n",
        "The classical transformer architecture.\n",
        "It takes the source and target tokens embeddings and\n",
        "do the forward pass through the encoder and decoder.\n",
        "\n",
        "**Translation Transformer**\n",
        "\n",
        "Compute the source and target tokens embeddings, and apply a final head to produce next token logits.\n",
        "The output must not be the softmax but just the logits, because we use the `nn.CrossEntropyLoss`.\n",
        "\n",
        "It also creates the *src_key_padding_mask*, the *tgt_key_padding_mask* and the *tgt_mask_attn*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGYVF34mvRNk"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = TransformerEncoder(d_model, dim_feedforward, num_encoder_layers, nhead, dropout)\n",
        "        self.decoder = TransformerDecoder(d_model, dim_feedforward, num_decoder_layers, nhead, dropout)\n",
        "\n",
        "    def forward(self, src, tgt, tgt_mask_attn, src_key_padding_mask, tgt_key_padding_mask):\n",
        "        memory = self.encoder(src, src_key_padding_mask)\n",
        "        output = self.decoder(memory, tgt, tgt_mask_attn, src_key_padding_mask, tgt_key_padding_mask)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class TranslationTransformer(nn.Module):\n",
        "    def __init__(self, n_tokens_src, n_tokens_tgt, n_heads, dim_embedding, dim_hidden, n_layers, dropout, src_pad_idx, tgt_pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        self.src_embedding = nn.Embedding(n_tokens_src, dim_embedding)\n",
        "        self.tgt_embedding = nn.Embedding(n_tokens_tgt, dim_embedding)\n",
        "        self.position_encoding = nn.Embedding(dim_embedding, dim_embedding)\n",
        "        self.transformer = Transformer(dim_embedding, n_heads, n_layers, n_layers, dim_hidden, dropout)\n",
        "        self.fc_out = nn.Linear(dim_embedding, n_tokens_tgt)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.tgt_pad_idx = tgt_pad_idx\n",
        "\n",
        "    def make_src_key_padding_mask(self, source):\n",
        "        return source == self.src_pad_idx\n",
        "\n",
        "    def make_tgt_key_padding_mask(self, target):\n",
        "        return target == self.tgt_pad_idx\n",
        "\n",
        "    def make_tgt_mask(self, tgt):\n",
        "        tgt_seq_len = tgt.shape[1]\n",
        "        tgt_mask = torch.triu(torch.ones((tgt_seq_len, tgt_seq_len), device=tgt.device), diagonal=1).bool()\n",
        "        return tgt_mask\n",
        "\n",
        "    def forward(self, source, target):\n",
        "        src_seq_len, tgt_seq_len = source.shape[1], target.shape[1]\n",
        "        src_positions = torch.arange(0, src_seq_len).unsqueeze(0).repeat(source.shape[0], 1).to(source.device)\n",
        "        tgt_positions = torch.arange(0, tgt_seq_len).unsqueeze(0).repeat(target.shape[0], 1).to(target.device)\n",
        "\n",
        "        src = self.dropout(self.src_embedding(source) + self.position_encoding(src_positions))\n",
        "        tgt = self.dropout(self.tgt_embedding(target) + self.position_encoding(tgt_positions))\n",
        "\n",
        "        src_key_padding_mask = self.make_src_key_padding_mask(source)\n",
        "        tgt_key_padding_mask = self.make_tgt_key_padding_mask(target)\n",
        "        tgt_mask_attn = self.make_tgt_mask(target)\n",
        "\n",
        "        transformer_output = self.transformer(src, tgt, tgt_mask_attn, src_key_padding_mask, tgt_key_padding_mask)\n",
        "\n",
        "        logits = self.fc_out(transformer_output)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql6jv2lAK-nF"
      },
      "source": [
        "# Greedy search\n",
        "\n",
        "Here you have to implement a geedy search to generate a target translation from a trained model and an input source string.\n",
        "The next token will simply be the most probable one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KMp7piKK905"
      },
      "outputs": [],
      "source": [
        "def greedy_search(model, source, src_vocab, tgt_vocab, src_tokenizer, device, max_sentence_length):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    tokens = src_tokenizer(source)\n",
        "    src_indexes = [src_vocab.stoi(token) for token in tokens]\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "    # Initialize target tensor with start of sequence token\n",
        "    tgt_indexes = [tgt_vocab.stoi(tgt_vocab.SOS_TOKEN)]\n",
        "    eos_token_idx = tgt_vocab.stoi(tgt_vocab.EOS_TOKEN)\n",
        "\n",
        "    for _ in range(max_sentence_length):\n",
        "        tgt_tensor = torch.LongTensor(tgt_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(src_tensor, tgt_tensor)\n",
        "\n",
        "        # Get the highest probability token and its index\n",
        "        _, next_token_idx = logits[:, -1, :].max(dim=-1)\n",
        "\n",
        "        next_token_idx = next_token_idx.item()\n",
        "        tgt_indexes.append(next_token_idx)\n",
        "\n",
        "        if next_token_idx == eos_token_idx:\n",
        "            break\n",
        "\n",
        "    tgt_tokens = [tgt_vocab.itos(idx) for idx in tgt_indexes]\n",
        "\n",
        "    sentence = ' '.join(tgt_tokens[1:])\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgGFG-uXue6w"
      },
      "source": [
        "# Beam search\n",
        "Beam search is a smarter way of producing a sequence of tokens from\n",
        "an autoregressive model than just using a greedy search.\n",
        "\n",
        "The greedy search always choose the most probable token as the unique\n",
        "and only next target token, and repeat this processus until the *\\<eos\\>* token is predicted.\n",
        "\n",
        "Instead, the beam search selects the k-most probable tokens at each step.\n",
        "From those k tokens, the current sequence is duplicated k times and the k tokens are appended to the k sequences to produce new k sequences.\n",
        "\n",
        "*You don't have to understand this code, but understanding this code once the TP is over could improve your torch tensors skills.*\n",
        "\n",
        "---\n",
        "\n",
        "**More explanations**\n",
        "\n",
        "Since it is done at each step, the number of sequences grows exponentially (k sequences after the first step, k² sequences after the second...).\n",
        "In order to keep the number of sequences low, we remove sequences except the top-s most likely sequences.\n",
        "To do that, we keep track of the likelihood of each sequence.\n",
        "\n",
        "Formally, we define $s = [s_1, ..., s_{N_s}]$ as the source sequence made of $N_s$ tokens.\n",
        "We also define $t^i = [t_1, ..., t_i]$ as the target sequence at the beginning of the step $i$.\n",
        "\n",
        "The output of the model parameterized by $\\theta$ is:\n",
        "\n",
        "$$\n",
        "T_{i+1} = p(t_{i+1} | s, t^i ; \\theta )\n",
        "$$\n",
        "\n",
        "Where $T_{i+1}$ is the distribution of the next token $t_{i+1}$.\n",
        "\n",
        "Then, we define the likelihood of a target sentence $t = [t_1, ..., t_{N_t}]$ as:\n",
        "\n",
        "$$\n",
        "L(t) = \\prod_{i=1}^{N_t - 1} p(t_{i+1} | s, t_{i}; \\theta )\n",
        "$$\n",
        "\n",
        "Pseudocode of the beam search:\n",
        "```\n",
        "source: [N_s source tokens]  # Shape of [total_source_tokens]\n",
        "target: [1, <bos> token]  # Shape of [n_sentences, current_target_tokens]\n",
        "target_prob: [1]  # Shape of [n_sentences]\n",
        "# We use `n_sentences` as the batch_size dimension\n",
        "\n",
        "while current_target_tokens <= max_target_length:\n",
        "    source = repeat(source, n_sentences)  # Shape of [n_sentences, total_source_tokens]\n",
        "    predicted = model(source, target)[:, -1]  # Predict the next token distributions of all the n_sentences\n",
        "    tokens_idx, tokens_prob = topk(predicted, k)\n",
        "\n",
        "    # Append the `n_sentences * k` tokens to the `n_sentences` sentences\n",
        "    target = repeat(target, k)  # Shape of [n_sentences * k, current_target_tokens]\n",
        "    target = append_tokens(target, tokens_idx)  # Shape of [n_sentences * k, current_target_tokens + 1]\n",
        "\n",
        "    # Update the sentences probabilities\n",
        "    target_prob = repeat(target_prob, k)  # Shape of [n_sentences * k]\n",
        "    target_prob *= tokens_prob\n",
        "\n",
        "    if n_sentences * k >= max_sentences:\n",
        "        target, target_prob = topk_prob(target, target_prob, k=max_sentences)\n",
        "    else:\n",
        "        n_sentences *= k\n",
        "\n",
        "    current_target_tokens += 1\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-GomgGTY2sV"
      },
      "outputs": [],
      "source": [
        "def beautify(sentence: str) -> str:\n",
        "    \"\"\"Removes useless spaces.\n",
        "    \"\"\"\n",
        "    punc = {'.', ',', ';'}\n",
        "    for p in punc:\n",
        "        sentence = sentence.replace(f' {p}', p)\n",
        "\n",
        "    links = {'-', \"'\"}\n",
        "    for l in links:\n",
        "        sentence = sentence.replace(f'{l} ', l)\n",
        "        sentence = sentence.replace(f' {l}', l)\n",
        "\n",
        "    return sentence\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9Q7qcvH2Chp"
      },
      "outputs": [],
      "source": [
        "def indices_terminated(\n",
        "        target: torch.FloatTensor,\n",
        "        eos_token: int\n",
        "    ) -> tuple:\n",
        "    \"\"\"Split the target sentences between the terminated and the non-terminated\n",
        "    sentence. Return the indices of those two groups.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        target: The sentences.\n",
        "            Shape of [batch_size, n_tokens].\n",
        "        eos_token: Value of the End-of-Sentence token.\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        terminated: Indices of the terminated sentences (who's got the eos_token).\n",
        "            Shape of [n_terminated, ].\n",
        "        non-terminated: Indices of the unfinished sentences.\n",
        "            Shape of [batch_size-n_terminated, ].\n",
        "    \"\"\"\n",
        "    terminated = [i for i, t in enumerate(target) if eos_token in t]\n",
        "    non_terminated = [i for i, t in enumerate(target) if eos_token not in t]\n",
        "    return torch.LongTensor(terminated), torch.LongTensor(non_terminated)\n",
        "\n",
        "\n",
        "def append_beams(\n",
        "        target: torch.FloatTensor,\n",
        "        beams: torch.FloatTensor\n",
        "    ) -> torch.FloatTensor:\n",
        "    \"\"\"Add the beam tokens to the current sentences.\n",
        "    Duplicate the sentences so one token is added per beam per batch.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        target: Batch of unfinished sentences.\n",
        "            Shape of [batch_size, n_tokens].\n",
        "        beams: Batch of beams for each sentences.\n",
        "            Shape of [batch_size, n_beams].\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        target: Batch of sentences with one beam per sentence.\n",
        "            Shape of [batch_size * n_beams, n_tokens+1].\n",
        "    \"\"\"\n",
        "    batch_size, n_beams = beams.shape\n",
        "    n_tokens = target.shape[1]\n",
        "\n",
        "    target = einops.repeat(target, 'b t -> b c t', c=n_beams)  # [batch_size, n_beams, n_tokens]\n",
        "    beams = beams.unsqueeze(dim=2)  # [batch_size, n_beams, 1]\n",
        "\n",
        "    target = torch.cat((target, beams), dim=2)  # [batch_size, n_beams, n_tokens+1]\n",
        "    target = target.view(batch_size*n_beams, n_tokens+1)  # [batch_size * n_beams, n_tokens+1]\n",
        "    return target\n",
        "\n",
        "\n",
        "def beam_search(\n",
        "        model: nn.Module,\n",
        "        source: str,\n",
        "        src_vocab: Vocab,\n",
        "        tgt_vocab: Vocab,\n",
        "        src_tokenizer,\n",
        "        device: str,\n",
        "        beam_width: int,\n",
        "        max_target: int,\n",
        "        max_sentence_length: int,\n",
        "    ) -> list:\n",
        "    \"\"\"Do a beam search to produce probable translations.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        model: The translation model. Assumes it produces linear score (before softmax).\n",
        "        source: The sentence to translate.\n",
        "        src_vocab: The source vocabulary.\n",
        "        tgt_vocab: The target vocabulary.\n",
        "        device: Device to which we make the inference.\n",
        "        beam_width: Number of top-k tokens we keep at each stage.\n",
        "        max_target: Maximum number of target sentences we keep at the end of each stage.\n",
        "        max_sentence_length: Maximum number of tokens for the translated sentence.\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        sentences: List of sentences orderer by their likelihood.\n",
        "    \"\"\"\n",
        "    src_tokens = ['<bos>'] + src_tokenizer(source) + ['<eos>']\n",
        "    src_tokens = src_vocab(src_tokens)\n",
        "\n",
        "    tgt_tokens = ['<bos>']\n",
        "    tgt_tokens = tgt_vocab(tgt_tokens)\n",
        "\n",
        "    # To tensor and add unitary batch dimension\n",
        "    src_tokens = torch.LongTensor(src_tokens).to(device)\n",
        "    tgt_tokens = torch.LongTensor(tgt_tokens).unsqueeze(dim=0).to(device)\n",
        "    target_probs = torch.FloatTensor([1]).to(device)\n",
        "    model.to(device)\n",
        "\n",
        "    EOS_IDX = tgt_vocab['<eos>']\n",
        "    with torch.no_grad():\n",
        "        while tgt_tokens.shape[1] < max_sentence_length:\n",
        "            batch_size, n_tokens = tgt_tokens.shape\n",
        "\n",
        "            # Get next beams\n",
        "            src = einops.repeat(src_tokens, 't -> b t', b=tgt_tokens.shape[0])\n",
        "            predicted = model.forward(src, tgt_tokens)\n",
        "            predicted = torch.softmax(predicted, dim=-1)\n",
        "            probs, predicted = predicted[:, -1].topk(k=beam_width, dim=-1)\n",
        "\n",
        "            # Separe between terminated sentences and the others\n",
        "            idx_terminated, idx_not_terminated = indices_terminated(tgt_tokens, EOS_IDX)\n",
        "            idx_terminated, idx_not_terminated = idx_terminated.to(device), idx_not_terminated.to(device)\n",
        "\n",
        "            tgt_terminated = torch.index_select(tgt_tokens, dim=0, index=idx_terminated)\n",
        "            tgt_probs_terminated = torch.index_select(target_probs, dim=0, index=idx_terminated)\n",
        "\n",
        "            filter_t = lambda t: torch.index_select(t, dim=0, index=idx_not_terminated)\n",
        "            tgt_others = filter_t(tgt_tokens)\n",
        "            tgt_probs_others = filter_t(target_probs)\n",
        "            predicted = filter_t(predicted)\n",
        "            probs = filter_t(probs)\n",
        "\n",
        "            # Add the top tokens to the previous target sentences\n",
        "            tgt_others = append_beams(tgt_others, predicted)\n",
        "\n",
        "            # Add padding to terminated target\n",
        "            padd = torch.zeros((len(tgt_terminated), 1), dtype=torch.long, device=device)\n",
        "            tgt_terminated = torch.cat(\n",
        "                (tgt_terminated, padd),\n",
        "                dim=1\n",
        "            )\n",
        "\n",
        "            # Update each target sentence probabilities\n",
        "            tgt_probs_others = torch.repeat_interleave(tgt_probs_others, beam_width)\n",
        "            tgt_probs_others *= probs.flatten()\n",
        "            tgt_probs_terminated *= 0.999  # Penalize short sequences overtime\n",
        "\n",
        "            # Group up the terminated and the others\n",
        "            target_probs = torch.cat(\n",
        "                (tgt_probs_others, tgt_probs_terminated),\n",
        "                dim=0\n",
        "            )\n",
        "            tgt_tokens = torch.cat(\n",
        "                (tgt_others, tgt_terminated),\n",
        "                dim=0\n",
        "            )\n",
        "\n",
        "            # Keep only the top `max_target` target sentences\n",
        "            if target_probs.shape[0] <= max_target:\n",
        "                continue\n",
        "\n",
        "            target_probs, indices = target_probs.topk(k=max_target, dim=0)\n",
        "            tgt_tokens = torch.index_select(tgt_tokens, dim=0, index=indices)\n",
        "\n",
        "    sentences = []\n",
        "    for tgt_sentence in tgt_tokens:\n",
        "        tgt_sentence = list(tgt_sentence)[1:]  # Remove <bos> token\n",
        "        tgt_sentence = list(takewhile(lambda t: t != EOS_IDX, tgt_sentence))\n",
        "        tgt_sentence = ' '.join(tgt_vocab.lookup_tokens(tgt_sentence))\n",
        "        sentences.append(tgt_sentence)\n",
        "\n",
        "    sentences = [beautify(s) for s in sentences]\n",
        "\n",
        "    # Join the sentences with their likelihood\n",
        "    sentences = [(s, p.item()) for s, p in zip(sentences, target_probs)]\n",
        "    # Sort the sentences by their likelihood\n",
        "    sentences = [(s, p) for s, p in sorted(sentences, key=lambda k: k[1], reverse=True)]\n",
        "\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVr2FuDcZxC6"
      },
      "source": [
        "# Training loop\n",
        "This is a basic training loop code. It takes a big configuration dictionnary to avoid never ending arguments in the functions.\n",
        "We use [Weights and Biases](https://wandb.ai/) to log the trainings.\n",
        "It logs every training informations and model performances in the cloud.\n",
        "You have to create an account to use it. Every accounts are free for individuals or research teams."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_logs(dataset_type: str, logs: dict):\n",
        "    \"\"\"Print the logs.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        dataset_type: Either \"Train\", \"Eval\", \"Test\" type.\n",
        "        logs: Containing the metric's name and value.\n",
        "    \"\"\"\n",
        "    desc = [\n",
        "        f'{name}: {value:.2f}'\n",
        "        for name, value in logs.items()\n",
        "    ]\n",
        "    desc = '\\t'.join(desc)\n",
        "    desc = f'{dataset_type} -\\t' + desc\n",
        "    desc = desc.expandtabs(5)\n",
        "    print(desc)\n",
        "\n",
        "\n",
        "def topk_accuracy(\n",
        "        real_tokens: torch.FloatTensor,\n",
        "        probs_tokens: torch.FloatTensor,\n",
        "        k: int,\n",
        "        tgt_pad_idx: int,\n",
        "    ) -> torch.FloatTensor:\n",
        "    \"\"\"Compute the top-k accuracy.\n",
        "    We ignore the PAD tokens.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        real_tokens: Real tokens of the target sentence.\n",
        "            Shape of [batch_size * n_tokens].\n",
        "        probs_tokens: Tokens probability predicted by the model.\n",
        "            Shape of [batch_size * n_tokens, n_target_vocabulary].\n",
        "        k: Top-k accuracy threshold.\n",
        "        src_pad_idx: Source padding index value.\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        acc: Scalar top-k accuracy value.\n",
        "    \"\"\"\n",
        "    total = (real_tokens != tgt_pad_idx).sum()\n",
        "\n",
        "    _, pred_tokens = probs_tokens.topk(k=k, dim=-1)            # [batch_size * n_tokens, k]\n",
        "    real_tokens = einops.repeat(real_tokens, 'b -> b k', k=k)  # [batch_size * n_tokens, k]\n",
        "\n",
        "    good = (pred_tokens == real_tokens) & (real_tokens != tgt_pad_idx)\n",
        "    acc = good.sum() / total\n",
        "    return acc\n",
        "\n",
        "\n",
        "def loss_batch(\n",
        "        model: nn.Module,\n",
        "        source: torch.LongTensor,\n",
        "        target: torch.LongTensor,\n",
        "        config: dict,\n",
        "    )-> dict:\n",
        "    \"\"\"Compute the metrics associated with this batch.\n",
        "    The metrics are:\n",
        "        - loss\n",
        "        - top-1 accuracy\n",
        "        - top-5 accuracy\n",
        "        - top-10 accuracy\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        model: The model to train.\n",
        "        source: Batch of source tokens.\n",
        "            Shape of [batch_size, n_src_tokens].\n",
        "        target: Batch of target tokens.\n",
        "            Shape of [batch_size, n_tgt_tokens].\n",
        "        config: Additional parameters.\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        metrics: Dictionnary containing evaluated metrics on this batch.\n",
        "    \"\"\"\n",
        "    device = config['device']\n",
        "    loss_fn = config['loss'].to(device)\n",
        "    metrics = dict()\n",
        "\n",
        "    source, target = source.to(device), target.to(device)\n",
        "    target_in, target_out = target[:, :-1], target[:, 1:]\n",
        "\n",
        "    # Loss\n",
        "    pred = model(source, target_in)      # [batch_size, n_tgt_tokens-1, n_vocab]\n",
        "    pred = pred.view(-1, pred.shape[2])  # [batch_size * (n_tgt_tokens - 1), n_vocab]\n",
        "    target_out = target_out.flatten()    # [batch_size * (n_tgt_tokens - 1),]\n",
        "    metrics['loss'] = loss_fn(pred, target_out)\n",
        "\n",
        "    # Accuracy - we ignore the padding predictions\n",
        "    for k in [1, 5, 10]:\n",
        "        metrics[f'top-{k}'] = topk_accuracy(target_out, pred, k, config['tgt_pad_idx'])\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def eval_model(model: nn.Module, dataloader: DataLoader, config: dict) -> dict:\n",
        "    \"\"\"Evaluate the model on the given dataloader.\n",
        "    \"\"\"\n",
        "    device = config['device']\n",
        "    logs = defaultdict(list)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for source, target in dataloader:\n",
        "            metrics = loss_batch(model, source, target, config)\n",
        "            for name, value in metrics.items():\n",
        "                logs[name].append(value.cpu().item())\n",
        "\n",
        "    for name, values in logs.items():\n",
        "        logs[name] = np.mean(values)\n",
        "    return logs\n",
        "\n",
        "\n",
        "def train_model(model: nn.Module, config: dict):\n",
        "    \"\"\"Train the model in a teacher forcing manner.\n",
        "    \"\"\"\n",
        "    train_loader, val_loader = config['train_loader'], config['val_loader']\n",
        "    train_dataset, val_dataset = train_loader.dataset.dataset, val_loader.dataset.dataset\n",
        "    optimizer = config['optimizer']\n",
        "    clip = config['clip']\n",
        "    device = config['device']\n",
        "\n",
        "    columns = ['epoch']\n",
        "    for mode in ['train', 'validation']:\n",
        "        columns += [\n",
        "            f'{mode} - {colname}'\n",
        "            for colname in ['source', 'target', 'predicted', 'likelihood']\n",
        "        ]\n",
        "    log_table = wandb.Table(columns=columns)\n",
        "\n",
        "\n",
        "    print(f'Starting training for {config[\"epochs\"]} epochs, using {device}.')\n",
        "    for e in range(config['epochs']):\n",
        "        print(f'\\nEpoch {e+1}')\n",
        "\n",
        "        model.to(device)\n",
        "        model.train()\n",
        "        logs = defaultdict(list)\n",
        "\n",
        "        for batch_id, (source, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            metrics = loss_batch(model, source, target, config)\n",
        "            loss = metrics['loss']\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            optimizer.step()\n",
        "\n",
        "            for name, value in metrics.items():\n",
        "                logs[name].append(value.cpu().item())  # Don't forget the '.item' to free the cuda memory\n",
        "\n",
        "            if batch_id % config['log_every'] == 0:\n",
        "                for name, value in logs.items():\n",
        "                    logs[name] = np.mean(value)\n",
        "\n",
        "                train_logs = {\n",
        "                    f'Train - {m}': v\n",
        "                    for m, v in logs.items()\n",
        "                }\n",
        "                wandb.log(train_logs)\n",
        "                logs = defaultdict(list)\n",
        "\n",
        "        # Logs\n",
        "        if len(logs) != 0:\n",
        "            for name, value in logs.items():\n",
        "                logs[name] = np.mean(value)\n",
        "            train_logs = {\n",
        "                f'Train - {m}': v\n",
        "                for m, v in logs.items()\n",
        "            }\n",
        "        else:\n",
        "            logs = {\n",
        "                m.split(' - ')[1]: v\n",
        "                for m, v in train_logs.items()\n",
        "            }\n",
        "\n",
        "        print_logs('Train', logs)\n",
        "\n",
        "        logs = eval_model(model, val_loader, config)\n",
        "        print_logs('Eval', logs)\n",
        "        val_logs = {\n",
        "            f'Validation - {m}': v\n",
        "            for m, v in logs.items()\n",
        "        }\n",
        "\n",
        "        val_source, val_target = val_dataset[ torch.randint(len(val_dataset), (1,)) ]\n",
        "        val_pred, val_prob = beam_search(\n",
        "            model,\n",
        "            val_source,\n",
        "            config['src_vocab'],\n",
        "            config['tgt_vocab'],\n",
        "            config['src_tokenizer'],\n",
        "            device,  # It can take a lot of VRAM\n",
        "            beam_width=10,\n",
        "            max_target=100,\n",
        "            max_sentence_length=config['max_sequence_length'],\n",
        "        )[0]\n",
        "        print(val_source)\n",
        "        print(val_pred)\n",
        "\n",
        "        logs = {**train_logs, **val_logs}  # Merge dictionnaries\n",
        "        wandb.log(logs)  # Upload to the WandB cloud\n",
        "\n",
        "        # Table logs\n",
        "        train_source, train_target = train_dataset[ torch.randint(len(train_dataset), (1,)) ]\n",
        "        train_pred, train_prob = beam_search(\n",
        "            model,\n",
        "            train_source,\n",
        "            config['src_vocab'],\n",
        "            config['tgt_vocab'],\n",
        "            config['src_tokenizer'],\n",
        "            device,  # It can take a lot of VRAM\n",
        "            beam_width=10,\n",
        "            max_target=100,\n",
        "            max_sentence_length=config['max_sequence_length'],\n",
        "        )[0]\n",
        "\n",
        "        data = [\n",
        "            e + 1,\n",
        "            train_source, train_target, train_pred, train_prob,\n",
        "            val_source, val_target, val_pred, val_prob,\n",
        "        ]\n",
        "        log_table.add_data(*data)\n",
        "\n",
        "    # Log the table at the end of the training\n",
        "    wandb.log({'Model predictions': log_table})"
      ],
      "metadata": {
        "id": "2Cvtm7L5dlD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YImgxCWjlWni"
      },
      "source": [
        "# Training the models\n",
        "We can now finally train the models.\n",
        "Choose the right hyperparameters, play with them and try to find\n",
        "ones that lead to good models and good training curves.\n",
        "Try to reach a loss under 1.0.\n",
        "\n",
        "So you know, it is possible to get descent results with approximately 20 epochs.\n",
        "With CUDA enabled, one epoch, even on a big model with a big dataset, shouldn't last more than 10 minutes.\n",
        "A normal epoch is between 1 to 5 minutes.\n",
        "\n",
        "*This is considering Colab Pro, we should try using free Colab to get better estimations.*\n",
        "\n",
        "---\n",
        "\n",
        "To test your implementations, it is easier to try your models\n",
        "in a CPU instance. Indeed, Colab reduces your GPU instances priority\n",
        "with the time you recently past using GPU instances. It would be\n",
        "sad to consume all your GPU time on implementation testing.\n",
        "Moreover, you should try your models on small datasets and with a small number of parameters.\n",
        "For exemple, you could set:\n",
        "```\n",
        "MAX_SEQ_LEN = 10\n",
        "MIN_TOK_FREQ = 20\n",
        "dim_embedding = 40\n",
        "dim_hidden = 60\n",
        "n_layers = 1\n",
        "```\n",
        "\n",
        "You usually don't want to log anything onto WandB when testing your implementation.\n",
        "To deactivate WandB without having to change any line of code, you can type `!wandb offline` in a cell.\n",
        "\n",
        "Once you have rightly implemented the models, you can train bigger models on bigger datasets.\n",
        "When you do this, do not forget to change the runtime as GPU (and use `!wandb online`)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WriScTUEsRHr",
        "outputId": "c3b18109-a633-4f6f-be56-4aa3d5af3642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "Tue Apr 11 05:08:20 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    58W / 400W |   1281MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!wandb login\n",
        "\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqmpxnO1lgDy",
        "outputId": "c7788fc2-3882-4d20-bd6f-dc7c20fd744c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English vocabulary size: 11,753\n",
            "French vocabulary size: 17,820\n",
            "\n",
            "Training examples: 196,176\n",
            "Validation examples: 21,797\n"
          ]
        }
      ],
      "source": [
        "# Instanciate the datasets\n",
        "\n",
        "MAX_SEQ_LEN = 60\n",
        "MIN_TOK_FREQ = 2\n",
        "train_dataset, val_dataset = build_datasets(\n",
        "    MAX_SEQ_LEN,\n",
        "    MIN_TOK_FREQ,\n",
        "    en_tokenizer,\n",
        "    fr_tokenizer,\n",
        "    train,\n",
        "    valid,\n",
        ")\n",
        "\n",
        "\n",
        "print(f'English vocabulary size: {len(train_dataset.en_vocab):,}')\n",
        "print(f'French vocabulary size: {len(train_dataset.fr_vocab):,}')\n",
        "\n",
        "print(f'\\nTraining examples: {len(train_dataset):,}')\n",
        "print(f'Validation examples: {len(val_dataset):,}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywFEpplOU5dn",
        "outputId": "294e2310-5069-4877-d771-68154b673597"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "Layer (type:depth-idx)                             Output Shape              Param #\n",
              "====================================================================================================\n",
              "TranslationTransformer                             [128, 60, 17820]          --\n",
              "├─Embedding: 1-1                                   [128, 60, 196]            2,303,588\n",
              "├─Embedding: 1-2                                   [128, 60, 196]            38,416\n",
              "├─Dropout: 1-3                                     [128, 60, 196]            --\n",
              "├─Embedding: 1-4                                   [128, 60, 196]            3,492,720\n",
              "├─Embedding: 1-5                                   [128, 60, 196]            (recursive)\n",
              "├─Dropout: 1-6                                     [128, 60, 196]            --\n",
              "├─Transformer: 1-7                                 [128, 60, 196]            --\n",
              "│    └─TransformerEncoder: 2-1                     [128, 60, 196]            --\n",
              "│    │    └─ModuleList: 3-1                        --                        768,108\n",
              "│    └─TransformerDecoder: 2-2                     [128, 60, 196]            --\n",
              "│    │    └─ModuleList: 3-2                        --                        1,232,628\n",
              "├─Linear: 1-8                                      [128, 60, 17820]          3,510,540\n",
              "====================================================================================================\n",
              "Total params: 11,346,000\n",
              "Trainable params: 11,346,000\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 1.46\n",
              "====================================================================================================\n",
              "Input size (MB): 0.12\n",
              "Forward/backward pass size (MB): 1923.81\n",
              "Params size (MB): 45.38\n",
              "Estimated Total Size (MB): 1969.32\n",
              "===================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Build the model, the dataloaders, optimizer and the loss function\n",
        "# Log every hyperparameters and arguments into the config dictionnary\n",
        "\n",
        "config = {\n",
        "    # General parameters\n",
        "    'epochs': 5,\n",
        "    'batch_size': 128,\n",
        "    'lr': 1e-3,\n",
        "    'betas': (0.9, 0.99),\n",
        "    'clip': 5,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "\n",
        "    # Model parameters\n",
        "    'n_tokens_src': len(train_dataset.en_vocab),\n",
        "    'n_tokens_tgt': len(train_dataset.fr_vocab),\n",
        "    'n_heads': 4,\n",
        "    'dim_embedding': 196,\n",
        "    'dim_hidden': 256,\n",
        "    'n_layers': 3,\n",
        "    'dropout': 0.1,\n",
        "    'model_type': 'GRU',\n",
        "\n",
        "    # Others\n",
        "    'max_sequence_length': MAX_SEQ_LEN,\n",
        "    'min_token_freq': MIN_TOK_FREQ,\n",
        "    'src_vocab': train_dataset.en_vocab,\n",
        "    'tgt_vocab': train_dataset.fr_vocab,\n",
        "    'src_tokenizer': en_tokenizer,\n",
        "    'tgt_tokenizer': fr_tokenizer,\n",
        "    'src_pad_idx': train_dataset.en_vocab['<pad>'],\n",
        "    'tgt_pad_idx': train_dataset.fr_vocab['<pad>'],\n",
        "    'seed': 0,\n",
        "    'log_every': 50,  # Number of batches between each wandb logs\n",
        "}\n",
        "\n",
        "torch.manual_seed(config['seed'])\n",
        "\n",
        "config['train_loader'] = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "\n",
        "    collate_fn=lambda batch: generate_batch(batch, config['src_pad_idx'], config['tgt_pad_idx'])\n",
        ")\n",
        "\n",
        "config['val_loader'] = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "\n",
        "\n",
        "    collate_fn=lambda batch: generate_batch(batch, config['src_pad_idx'], config['tgt_pad_idx'])\n",
        ")\n",
        "\"\"\"\n",
        "model = TranslationRNN(\n",
        "    config['n_tokens_src'],\n",
        "    config['n_tokens_tgt'],\n",
        "    config['dim_embedding'],\n",
        "    config['dim_hidden'],\n",
        "    config['n_layers'],\n",
        "    config['dropout'],\n",
        "    config['src_pad_idx'],\n",
        "    config['tgt_pad_idx'],\n",
        "    config['model_type'],\n",
        ")\n",
        "\"\"\"\n",
        "model = TranslationTransformer(\n",
        "    config['n_tokens_src'],\n",
        "    config['n_tokens_tgt'],\n",
        "    config['n_heads'],\n",
        "    config['dim_embedding'],\n",
        "    config['dim_hidden'],\n",
        "    config['n_layers'],\n",
        "    config['dropout'],\n",
        "    config['src_pad_idx'],\n",
        "    config['tgt_pad_idx'],\n",
        ")\n",
        "\n",
        "\n",
        "config['optimizer'] = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=config['lr'],\n",
        "    betas=config['betas'],\n",
        ")\n",
        "\n",
        "weight_classes = torch.ones(config['n_tokens_tgt'], dtype=torch.float)\n",
        "weight_classes[config['tgt_vocab']['<unk>']] = 0.1  # Lower the importance of that class\n",
        "config['loss'] = nn.CrossEntropyLoss(\n",
        "    weight=weight_classes,\n",
        "    ignore_index=config['tgt_pad_idx'],  # We do not have to learn those\n",
        ")\n",
        "\n",
        "summary(\n",
        "    model,\n",
        "    input_size=[\n",
        "        (config['batch_size'], config['max_sequence_length']),\n",
        "        (config['batch_size'], config['max_sequence_length'])\n",
        "    ],\n",
        "    dtypes=[torch.long, torch.long],\n",
        "    depth=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wandb online\n",
        "!wandb login --relogin\n",
        "!WANDB_MODE=online"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmVZrQFbZYLe",
        "outputId": "7c927052-5faa-4a01-f37b-4e7b789e8f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RNN"
      ],
      "metadata": {
        "id": "zFiFkFyCzopl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN\n",
        "!wandb online\n",
        "with wandb.init(\n",
        "        config=config,\n",
        "        project='INF8225 - TP3',  # Title of your project\n",
        "\n",
        "        group='Transformer - small',  # In what group of runs do you want this run to be in?\n",
        "        save_code=True,\n",
        "\n",
        "    ):\n",
        "    train_model(model, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8965WN-XvOGC",
        "outputId": "f43c285a-ce80-42b3-a0da-079c2c4a5459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W&B online. Running your script from this directory will now sync to the cloud.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230411_003541-tzos9qpt</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/tzos9qpt' target=\"_blank\">fresh-waterfall-37</a></strong> to <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/tzos9qpt' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/tzos9qpt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 3.37     top-1: 0.38    top-5: 0.57    top-10: 0.66\n",
            "Eval -    loss: 3.28     top-1: 0.38    top-5: 0.58    top-10: 0.66\n",
            "Tom enjoys telling jokes.\n",
            "Je n'ai pas l'intention de faire ça.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 3.18     top-1: 0.39    top-5: 0.59    top-10: 0.68\n",
            "Eval -    loss: 3.12     top-1: 0.40    top-5: 0.59    top-10: 0.68\n",
            "Berlin is in Germany.\n",
            "Je ne sais pas quoi faire.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 3.06     top-1: 0.40    top-5: 0.61    top-10: 0.70\n",
            "Eval -    loss: 3.04     top-1: 0.40    top-5: 0.60    top-10: 0.69\n",
            "The dog drank some water and went away.\n",
            "Je ne sais pas quoi faire.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 2.91     top-1: 0.42    top-5: 0.63    top-10: 0.71\n",
            "Eval -    loss: 2.93     top-1: 0.42    top-5: 0.62    top-10: 0.70\n",
            "Certain conditions may apply.\n",
            "Il y a quelque chose que je veux faire.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 2.94     top-1: 0.42    top-5: 0.62    top-10: 0.71\n",
            "Eval -    loss: 2.92     top-1: 0.42    top-5: 0.62    top-10: 0.71\n",
            "I have to support a large family.\n",
            "Je ne sais pas ce que je veux dire.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██████▇▇█████</td></tr><tr><td>Train - top-10</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇██████████▇██████</td></tr><tr><td>Train - top-5</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████▇██████</td></tr><tr><td>Validation - loss</td><td>█▅▃▁▁</td></tr><tr><td>Validation - top-1</td><td>▁▄▅██</td></tr><tr><td>Validation - top-10</td><td>▁▄▆██</td></tr><tr><td>Validation - top-5</td><td>▁▄▅██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>2.93837</td></tr><tr><td>Train - top-1</td><td>0.41973</td></tr><tr><td>Train - top-10</td><td>0.70628</td></tr><tr><td>Train - top-5</td><td>0.62062</td></tr><tr><td>Validation - loss</td><td>2.92229</td></tr><tr><td>Validation - top-1</td><td>0.41729</td></tr><tr><td>Validation - top-10</td><td>0.70712</td></tr><tr><td>Validation - top-5</td><td>0.62187</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fresh-waterfall-37</strong> at: <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/tzos9qpt' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/tzos9qpt</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230411_003541-tzos9qpt/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GRU"
      ],
      "metadata": {
        "id": "CPGsZeu5zsIX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "maOTVtk4acxD",
        "outputId": "49648b2a-d0ee-49b1-a159-b4e663e7c156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W&B online. Running your script from this directory will now sync to the cloud.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maminekhouiy\u001b[0m (\u001b[33mteam-amine\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230410_232938-fli4wtkk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/fli4wtkk' target=\"_blank\">dauntless-wildflower-36</a></strong> to <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/fli4wtkk' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/fli4wtkk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.38     top-1: 0.55    top-5: 0.74    top-10: 0.79\n",
            "Eval -    loss: 2.28     top-1: 0.56    top-5: 0.74    top-10: 0.79\n",
            "They manage to get along without much money.\n",
            "Ils ont l'intention de rester plus de temps.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.89     top-1: 0.62    top-5: 0.80    top-10: 0.85\n",
            "Eval -    loss: 1.81     top-1: 0.63    top-5: 0.81    top-10: 0.85\n",
            "Don't speak so fast, please.\n",
            "Ne parle pas si vite, s'il te plait.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.64     top-1: 0.66    top-5: 0.84    top-10: 0.88\n",
            "Eval -    loss: 1.59     top-1: 0.66    top-5: 0.84    top-10: 0.88\n",
            "Stop treating me like a child.\n",
            "Arrête de me mettre comme un enfant.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.46     top-1: 0.69    top-5: 0.86    top-10: 0.90\n",
            "Eval -    loss: 1.47     top-1: 0.68    top-5: 0.86    top-10: 0.89\n",
            "You're worried, aren't you?\n",
            "Tu es inquiète, n'est-ce pas ?\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.34     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "Eval -    loss: 1.40     top-1: 0.69    top-5: 0.87    top-10: 0.90\n",
            "Is there a school bus?\n",
            "Y a-t-il un école en Australie ?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▅▇▇█</td></tr><tr><td>Validation - top-5</td><td>▁▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.34399</td></tr><tr><td>Train - top-1</td><td>0.70187</td></tr><tr><td>Train - top-10</td><td>0.91149</td></tr><tr><td>Train - top-5</td><td>0.87775</td></tr><tr><td>Validation - loss</td><td>1.40051</td></tr><tr><td>Validation - top-1</td><td>0.69308</td></tr><tr><td>Validation - top-10</td><td>0.9003</td></tr><tr><td>Validation - top-5</td><td>0.86756</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dauntless-wildflower-36</strong> at: <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/fli4wtkk' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/fli4wtkk</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230410_232938-fli4wtkk/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#GRU\n",
        "!wandb online\n",
        "with wandb.init(\n",
        "        config=config,\n",
        "        project='INF8225 - TP3',  # Title of your project\n",
        "\n",
        "        group='Transformer - small',  # In what group of runs do you want this run to be in?\n",
        "        save_code=True,\n",
        "\n",
        "    ):\n",
        "    train_model(model, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transformer\n"
      ],
      "metadata": {
        "id": "CVMOwm_c18YA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wandb online > /dev/null  # online / offline to activate or deactivate WandB logging\n",
        "\n",
        "with wandb.init(\n",
        "        config=config,\n",
        "        project='INF8225 - TP3',  # Title of your project\n",
        "\n",
        "        group='Transformer - small',  # In what group of runs do you want this run to be in?\n",
        "        save_code=True,\n",
        "\n",
        "    ):\n",
        "    train_model(model, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7acfdb23d5394f4bb12201d64f2b48a4",
            "00908a8b80564b5f8991b07f08f7541e",
            "19994336463f44a2aa6d17c48833592b",
            "bb42ac1cdc134d5da2adf56bb46ad99d",
            "34cfbe39a7804a94ac64f732c57ce043",
            "ed7856247c7c41bd94c6a68801a71800",
            "312fc6cf4ad94fb7ae2b8b47d2b164bc",
            "a0ae3b31fd054c7d9ee1f86058b3e32e"
          ]
        },
        "id": "qiSSfff01g7Q",
        "outputId": "5c6778a8-803a-4586-a99b-318ec09fbaec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230411_102205-kgs8yg6j</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/kgs8yg6j' target=\"_blank\">genial-music-49</a></strong> to <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/kgs8yg6j' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/kgs8yg6j</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 1.77     top-1: 0.65    top-5: 0.84    top-10: 0.87\n",
            "Eval -    loss: 1.56     top-1: 0.67    top-5: 0.86    top-10: 0.89\n",
            "I didn't know what time I was supposed to leave.\n",
            "Je ne savais pas ce que j'étais censé partir.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.41     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "Eval -    loss: 1.27     top-1: 0.72    top-5: 0.89    top-10: 0.92\n",
            "We appreciate the advice.\n",
            "Nous apprécions les conseils.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.24     top-1: 0.72    top-5: 0.90    top-10: 0.93\n",
            "Eval -    loss: 1.15     top-1: 0.74    top-5: 0.90    top-10: 0.93\n",
            "I've already paid you.\n",
            "Je t'ai déjà payé.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.14     top-1: 0.74    top-5: 0.91    top-10: 0.94\n",
            "Eval -    loss: 1.08     top-1: 0.75    top-5: 0.91    top-10: 0.94\n",
            "You don't seem to understand.\n",
            "Vous ne semblez pas comprendre.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.11     top-1: 0.75    top-5: 0.91    top-10: 0.94\n",
            "Eval -    loss: 1.04     top-1: 0.76    top-5: 0.92    top-10: 0.94\n",
            "I recovered.\n",
            "Je me suis rétabli.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.365 MB of 0.365 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7acfdb23d5394f4bb12201d64f2b48a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>Train - top-10</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▂▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▅▇▇█</td></tr><tr><td>Validation - top-5</td><td>▁▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.10562</td></tr><tr><td>Train - top-1</td><td>0.74527</td></tr><tr><td>Train - top-10</td><td>0.94005</td></tr><tr><td>Train - top-5</td><td>0.91318</td></tr><tr><td>Validation - loss</td><td>1.03594</td></tr><tr><td>Validation - top-1</td><td>0.75981</td></tr><tr><td>Validation - top-10</td><td>0.94079</td></tr><tr><td>Validation - top-5</td><td>0.91842</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">genial-music-49</strong> at: <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/kgs8yg6j' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/kgs8yg6j</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230411_102205-kgs8yg6j/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K6GtgWQwzwGO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PFIyvKUefdV",
        "outputId": "a682018b-bd74-4a9f-cfca-30aa8ca58c3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0. (19.64876%) \t Il est possible d'essayer ton travail ici.\n",
            "1. (13.85630%) \t C'est possible d'essayer ton travail ici.\n",
            "2. (9.83911%) \t Il est possible d'essayer votre travail ici.\n",
            "3. (5.54668%) \t C'est possible d'essayer votre travail ici.\n",
            "4. (0.97218%) \t Il est possible d'essayer le travail ici.\n"
          ]
        }
      ],
      "source": [
        "sentence = \"It is possible to try your work here.\"\n",
        "\n",
        "preds = beam_search(\n",
        "    model,\n",
        "    sentence,\n",
        "    config['src_vocab'],\n",
        "    config['tgt_vocab'],\n",
        "    config['src_tokenizer'],\n",
        "    config['device'],\n",
        "    beam_width=10,\n",
        "    max_target=100,\n",
        "    max_sentence_length=config['max_sequence_length']\n",
        ")[:5]\n",
        "\n",
        "for i, (translation, likelihood) in enumerate(preds):\n",
        "    print(f'{i}. ({likelihood*100:.5f}%) \\t {translation}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHhixEEGzWRR"
      },
      "source": [
        "# Questions\n",
        "1. Explain the differences between Vanilla RNN, GRU-RNN, and Transformers.\n",
        "2. Why is positionnal encoding necessary in Transformers and not in RNNs?\n",
        "3. Describe the preprocessing process. Detail how the initial dataset is processed before being fed to the translation models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3tQdusIjPCy"
      },
      "source": [
        "# Small report - experiments\n",
        "Once everything is working fine, you can explore aspects of these models and do some research of your own into how they behave.\n",
        "\n",
        "For exemple, you can experiment with the hyperparameters.\n",
        "What are the effect of the differents hyperparameters with the final model performance? What about training time?\n",
        "\n",
        "What are some other metrics you could have for machine translation? Can you compute them and add them to your WandB report?\n",
        "\n",
        "Those are only examples, you can do whatever you think will be interesting.\n",
        "This part account for many points, *feel free to go wild!*\n",
        "\n",
        "---\n",
        "*Make a concise report about your experiments here.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RNN"
      ],
      "metadata": {
        "id": "R9B4bPZf2T25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wandb online\n",
        "with wandb.init(\n",
        "        config=config,\n",
        "        project='INF8225 - TP3',  # Title of your project\n",
        "\n",
        "        group='Transformer - small',  # In what group of runs do you want this run to be in?\n",
        "        save_code=True,\n",
        "\n",
        "    ):\n",
        "  for batchsize in [64,128,256]:\n",
        "    print('batch size',batchsize)\n",
        "    config['batch_size'] = batchsize\n",
        "    train_model(model, config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BzOIQfEdpCDN",
        "outputId": "7c262967-f5c4-46d1-e550-964f46786590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W&B online. Running your script from this directory will now sync to the cloud.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230411_051157-aecoqefs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/aecoqefs' target=\"_blank\">chocolate-rain-39</a></strong> to <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/aecoqefs' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/aecoqefs</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch size 64\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 3.26     top-1: 0.38    top-5: 0.58    top-10: 0.67\n",
            "Eval -    loss: 3.18     top-1: 0.39    top-5: 0.59    top-10: 0.67\n",
            "I need to go to work.\n",
            "Je ne sais pas comment faire ça.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 3.09     top-1: 0.40    top-5: 0.61    top-10: 0.69\n",
            "Eval -    loss: 3.08     top-1: 0.40    top-5: 0.60    top-10: 0.69\n",
            "I made that for you.\n",
            "Je ne peux pas le faire.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 3.00     top-1: 0.41    top-5: 0.61    top-10: 0.70\n",
            "Eval -    loss: 3.00     top-1: 0.41    top-5: 0.61    top-10: 0.70\n",
            "I'll be back in a little bit.\n",
            "Je ne sais pas ce que tu as à faire.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 2.95     top-1: 0.42    top-5: 0.62    top-10: 0.71\n",
            "Eval -    loss: 2.95     top-1: 0.41    top-5: 0.62    top-10: 0.71\n",
            "I thought you'd been killed. I'm glad I was wrong.\n",
            "Je ne pense pas qu'il va pleuvoir.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 2.91     top-1: 0.42    top-5: 0.62    top-10: 0.71\n",
            "Eval -    loss: 2.91     top-1: 0.42    top-5: 0.62    top-10: 0.71\n",
            "You're the one who trained me.\n",
            "Je n'arrive pas à croire que vous soyez ici.\n",
            "batch size 128\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.86     top-1: 0.42    top-5: 0.63    top-10: 0.72\n",
            "Eval -    loss: 2.89     top-1: 0.42    top-5: 0.62    top-10: 0.71\n",
            "It's easy to acquire bad habits.\n",
            "Je ne sais pas ce que tu as à faire.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 2.89     top-1: 0.42    top-5: 0.63    top-10: 0.72\n",
            "Eval -    loss: 2.88     top-1: 0.42    top-5: 0.63    top-10: 0.72\n",
            "I want to find a good job.\n",
            "Je ne sais pas ce que je vais faire.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 2.84     top-1: 0.43    top-5: 0.64    top-10: 0.72\n",
            "Eval -    loss: 2.86     top-1: 0.43    top-5: 0.63    top-10: 0.72\n",
            "I still live at my dad's place.\n",
            "Je ne pense pas que ce soit une bonne idée.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 2.82     top-1: 0.43    top-5: 0.64    top-10: 0.72\n",
            "Eval -    loss: 2.84     top-1: 0.43    top-5: 0.63    top-10: 0.72\n",
            "Please remember to mail this letter.\n",
            "Je ne sais pas comment faire ça.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 2.75     top-1: 0.44    top-5: 0.65    top-10: 0.73\n",
            "Eval -    loss: 2.81     top-1: 0.43    top-5: 0.64    top-10: 0.72\n",
            "I've been expecting you.\n",
            "J'ignore ce que je vais faire.\n",
            "batch size 256\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.70     top-1: 0.44    top-5: 0.65    top-10: 0.74\n",
            "Eval -    loss: 2.78     top-1: 0.44    top-5: 0.64    top-10: 0.73\n",
            "I've been there a dozen times.\n",
            "Je ne pense pas que ce soit une bonne idée.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 2.68     top-1: 0.45    top-5: 0.66    top-10: 0.74\n",
            "Eval -    loss: 2.77     top-1: 0.44    top-5: 0.65    top-10: 0.73\n",
            "I don't often get invited to parties.\n",
            "Je ne pense pas que ce soit une bonne idée.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 2.69     top-1: 0.44    top-5: 0.65    top-10: 0.74\n",
            "Eval -    loss: 2.77     top-1: 0.44    top-5: 0.65    top-10: 0.73\n",
            "Give them to me.\n",
            "J'aimerais vous poser quelques questions.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 2.68     top-1: 0.44    top-5: 0.66    top-10: 0.74\n",
            "Eval -    loss: 2.76     top-1: 0.44    top-5: 0.65    top-10: 0.73\n",
            "She is a most beautiful lady.\n",
            "Je ne sais pas quoi faire.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 2.66     top-1: 0.45    top-5: 0.66    top-10: 0.74\n",
            "Eval -    loss: 2.76     top-1: 0.44    top-5: 0.65    top-10: 0.73\n",
            "I go to any party I am invited to.\n",
            "Je ne veux pas que tu fasses ça.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▇▆▅▅▅▅▅▄▄▄▃▄▄▃▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂</td></tr><tr><td>Train - top-1</td><td>▁▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▆▆▇▆▇▇▇█▇▇▇▇▇█████</td></tr><tr><td>Train - top-10</td><td>▁▂▃▃▃▄▄▄▅▅▅▆▅▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇</td></tr><tr><td>Train - top-5</td><td>▁▂▃▃▃▄▄▄▄▅▅▅▅▅▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>Validation - loss</td><td>█▆▅▄▄▃▃▃▂▂▁▁▁▁▁</td></tr><tr><td>Validation - top-1</td><td>▁▂▃▄▅▅▆▆▆▇█████</td></tr><tr><td>Validation - top-10</td><td>▁▃▄▅▅▆▆▆▇▇▇████</td></tr><tr><td>Validation - top-5</td><td>▁▃▄▅▅▅▆▆▆▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>2.65793</td></tr><tr><td>Train - top-1</td><td>0.4471</td></tr><tr><td>Train - top-10</td><td>0.74263</td></tr><tr><td>Train - top-5</td><td>0.65972</td></tr><tr><td>Validation - loss</td><td>2.75595</td></tr><tr><td>Validation - top-1</td><td>0.43821</td></tr><tr><td>Validation - top-10</td><td>0.73052</td></tr><tr><td>Validation - top-5</td><td>0.64879</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">chocolate-rain-39</strong> at: <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/aecoqefs' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/aecoqefs</a><br/>Synced 5 W&B file(s), 3 media file(s), 5 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230411_051157-aecoqefs/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb online\n",
        "with wandb.init(\n",
        "        config=config,\n",
        "        project='INF8225 - TP3',  # Title of your project\n",
        "\n",
        "        group='Transformer - small',  # In what group of runs do you want this run to be in?\n",
        "        save_code=True,\n",
        "\n",
        "    ):\n",
        "  for nlayer in [2,4]:\n",
        "    print('n_layers',nlayer)\n",
        "    config['n_layers'] = nlayer\n",
        "    train_model(model, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6f9b12c56ad94315b326e39a0497c2f0",
            "e146415ca7054d758ef277951645dbd9",
            "00837fb64644444fa57a62f2ce48a20f",
            "933fde9f7c8a48dc88d2cf4e8d0c96fe",
            "1b3011330b0646a3ab0612dd0f51e3c5",
            "de659010b610450084257fcf6dcc5fb5",
            "2b0e7d7f0202417bbe8607d7a4ed4151",
            "6cc01f7dfd2b4bfa907ff71cc27e1f2d"
          ]
        },
        "id": "CjlJwagOriMc",
        "outputId": "3cdcbc54-e35b-441b-aaff-ef7925710b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W&B online. Running your script from this directory will now sync to the cloud.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230411_060131-r3csdl6y</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/r3csdl6y' target=\"_blank\">peach-oath-42</a></strong> to <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/r3csdl6y' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/r3csdl6y</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_layers 2\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 3.37     top-1: 0.38    top-5: 0.57    top-10: 0.66\n",
            "Eval -    loss: 3.28     top-1: 0.38    top-5: 0.58    top-10: 0.66\n",
            "Tom enjoys telling jokes.\n",
            "Je n'ai pas l'intention de faire ça.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 3.18     top-1: 0.39    top-5: 0.59    top-10: 0.68\n",
            "Eval -    loss: 3.12     top-1: 0.40    top-5: 0.59    top-10: 0.68\n",
            "Berlin is in Germany.\n",
            "Je ne sais pas quoi faire.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 3.06     top-1: 0.40    top-5: 0.61    top-10: 0.70\n",
            "Eval -    loss: 3.04     top-1: 0.40    top-5: 0.60    top-10: 0.69\n",
            "The dog drank some water and went away.\n",
            "Je ne sais pas quoi faire.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 2.91     top-1: 0.42    top-5: 0.63    top-10: 0.71\n",
            "Eval -    loss: 2.93     top-1: 0.42    top-5: 0.62    top-10: 0.70\n",
            "Certain conditions may apply.\n",
            "Il y a quelque chose que je veux faire.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 2.94     top-1: 0.42    top-5: 0.62    top-10: 0.71\n",
            "Eval -    loss: 2.92     top-1: 0.42    top-5: 0.62    top-10: 0.71\n",
            "I have to support a large family.\n",
            "Je ne sais pas ce que je veux dire.\n",
            "n_layers 4\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.89     top-1: 0.42    top-5: 0.63    top-10: 0.71\n",
            "Eval -    loss: 2.89     top-1: 0.42    top-5: 0.63    top-10: 0.71\n",
            "I can't express my feelings.\n",
            "Je ne pense pas que ce soit une bonne idée.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 2.86     top-1: 0.43    top-5: 0.63    top-10: 0.71\n",
            "Eval -    loss: 2.86     top-1: 0.43    top-5: 0.63    top-10: 0.72\n",
            "This is no big deal.\n",
            "«   Comment es-tu née ?\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 2.82     top-1: 0.43    top-5: 0.64    top-10: 0.72\n",
            "Eval -    loss: 2.86     top-1: 0.43    top-5: 0.63    top-10: 0.72\n",
            "The regulation was abolished, but then it was reenacted.\n",
            "C'est ce que j'ai dit.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 2.80     top-1: 0.43    top-5: 0.64    top-10: 0.73\n",
            "Eval -    loss: 2.83     top-1: 0.43    top-5: 0.64    top-10: 0.72\n",
            "Tom was starting to feel a little uncomfortable.\n",
            "Il y a quelque chose que tu veux.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 2.77     top-1: 0.44    top-5: 0.64    top-10: 0.73\n",
            "Eval -    loss: 2.83     top-1: 0.43    top-5: 0.64    top-10: 0.72\n",
            "Workers at the company went on a strike.\n",
            "Il y a quelque chose qui cloche.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.369 MB of 0.369 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f9b12c56ad94315b326e39a0497c2f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███▇████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇████████████</td></tr><tr><td>Validation - loss</td><td>█▅▄▂▂▂▁▁▁▁</td></tr><tr><td>Validation - top-1</td><td>▁▃▄▆▆▇▇▇██</td></tr><tr><td>Validation - top-10</td><td>▁▃▅▆▆▇▇███</td></tr><tr><td>Validation - top-5</td><td>▁▃▄▆▆▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>2.77061</td></tr><tr><td>Train - top-1</td><td>0.43577</td></tr><tr><td>Train - top-10</td><td>0.72723</td></tr><tr><td>Train - top-5</td><td>0.64474</td></tr><tr><td>Validation - loss</td><td>2.83298</td></tr><tr><td>Validation - top-1</td><td>0.43049</td></tr><tr><td>Validation - top-10</td><td>0.72037</td></tr><tr><td>Validation - top-5</td><td>0.63608</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">peach-oath-42</strong> at: <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/r3csdl6y' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/r3csdl6y</a><br/>Synced 5 W&B file(s), 2 media file(s), 4 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230411_060131-r3csdl6y/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb online\n",
        "with wandb.init(\n",
        "        config=config,\n",
        "        project='INF8225 - TP3',  # Title of your project\n",
        "\n",
        "        group='Transformer - small',  # In what group of runs do you want this run to be in?\n",
        "        save_code=True,\n",
        "\n",
        "    ):\n",
        "  for dimembedding in [100,400]:\n",
        "    print('dim_embedding',dimembedding)\n",
        "    config['dim_embedding'] = dimembedding\n",
        "    train_model(model, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "70a7bc0dbf0940deb08c3465140fcfb1",
            "85960e44b13e4c35990ff24555b643f9",
            "eef67b9fa4cb4c1bb2ebe49f2095949e",
            "4c8ac17e808d4e658e91353ff7c69033",
            "205908a94f8842d28d22e7f8380f8353",
            "58d6e5366601491aa08bcb51de5d9a8a",
            "a1b0c6cadba944e394f1a0f8127d18af",
            "39c7eecd6e2c4bd3868dc2b58921ffad",
            "832b7977e98148c18d38e000e4caa381",
            "ea030a276f404323adbe6868297018ef",
            "6d7e84ef033f4042ac7130010077c50b",
            "eab5ac9fc1a04e29bf9f732b02fafd8f",
            "f09a51cac7e346d9bc2dec7efaef2b72",
            "a575bc47b3a74c12bcd4fbee2444324e",
            "0b199ae94b2a4728b0fa5339a742639b",
            "6b5d8a83db394269b360e71cad0725bc"
          ]
        },
        "id": "AMnJdL6K_yYi",
        "outputId": "40f6e4a8-2a95-477d-f074-180e70edabd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W&B online. Running your script from this directory will now sync to the cloud.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:ke0h761y) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='1.318 MB of 1.318 MB uploaded (0.109 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70a7bc0dbf0940deb08c3465140fcfb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▁</td></tr><tr><td>Train - top-1</td><td>▁█</td></tr><tr><td>Train - top-10</td><td>▁█</td></tr><tr><td>Train - top-5</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>0.8784</td></tr><tr><td>Train - top-1</td><td>0.77376</td></tr><tr><td>Train - top-10</td><td>0.95431</td></tr><tr><td>Train - top-5</td><td>0.93123</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">avid-field-46</strong> at: <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/ke0h761y' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/ke0h761y</a><br/>Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230411_085416-ke0h761y/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:ke0h761y). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230411_085603-li4aot6u</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/li4aot6u' target=\"_blank\">vocal-flower-47</a></strong> to <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/li4aot6u' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/li4aot6u</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dim_embedding 100\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 3.37     top-1: 0.38    top-5: 0.57    top-10: 0.66\n",
            "Eval -    loss: 3.28     top-1: 0.38    top-5: 0.58    top-10: 0.66\n",
            "Tom enjoys telling jokes.\n",
            "Je n'ai pas l'intention de faire ça.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 3.18     top-1: 0.39    top-5: 0.59    top-10: 0.68\n",
            "Eval -    loss: 3.12     top-1: 0.40    top-5: 0.59    top-10: 0.68\n",
            "Berlin is in Germany.\n",
            "Je ne sais pas quoi faire.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 3.06     top-1: 0.40    top-5: 0.61    top-10: 0.70\n",
            "Eval -    loss: 3.04     top-1: 0.40    top-5: 0.60    top-10: 0.69\n",
            "The dog drank some water and went away.\n",
            "Je ne sais pas quoi faire.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 2.91     top-1: 0.42    top-5: 0.63    top-10: 0.71\n",
            "Eval -    loss: 2.93     top-1: 0.42    top-5: 0.62    top-10: 0.70\n",
            "Certain conditions may apply.\n",
            "Il y a quelque chose que je veux faire.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 2.94     top-1: 0.42    top-5: 0.62    top-10: 0.71\n",
            "Eval -    loss: 2.92     top-1: 0.42    top-5: 0.62    top-10: 0.71\n",
            "I have to support a large family.\n",
            "Je ne sais pas ce que je veux dire.\n",
            "dim_embedding 400\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.89     top-1: 0.42    top-5: 0.63    top-10: 0.71\n",
            "Eval -    loss: 2.89     top-1: 0.42    top-5: 0.63    top-10: 0.71\n",
            "I can't express my feelings.\n",
            "Je ne pense pas que ce soit une bonne idée.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 2.86     top-1: 0.43    top-5: 0.63    top-10: 0.71\n",
            "Eval -    loss: 2.86     top-1: 0.43    top-5: 0.63    top-10: 0.72\n",
            "This is no big deal.\n",
            "«   Comment es-tu née ?\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 2.82     top-1: 0.43    top-5: 0.64    top-10: 0.72\n",
            "Eval -    loss: 2.86     top-1: 0.43    top-5: 0.63    top-10: 0.72\n",
            "The regulation was abolished, but then it was reenacted.\n",
            "C'est ce que j'ai dit.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 2.80     top-1: 0.43    top-5: 0.64    top-10: 0.73\n",
            "Eval -    loss: 2.83     top-1: 0.43    top-5: 0.64    top-10: 0.72\n",
            "Tom was starting to feel a little uncomfortable.\n",
            "Il y a quelque chose que tu veux.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 2.77     top-1: 0.44    top-5: 0.64    top-10: 0.73\n",
            "Eval -    loss: 2.83     top-1: 0.43    top-5: 0.64    top-10: 0.72\n",
            "Workers at the company went on a strike.\n",
            "Il y a quelque chose qui cloche.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.009 MB of 0.011 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.848690…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "832b7977e98148c18d38e000e4caa381"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███▇████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇████████████</td></tr><tr><td>Validation - loss</td><td>█▅▄▂▂▂▁▁▁▁</td></tr><tr><td>Validation - top-1</td><td>▁▃▄▆▆▇▇▇██</td></tr><tr><td>Validation - top-10</td><td>▁▃▅▆▆▇▇███</td></tr><tr><td>Validation - top-5</td><td>▁▃▄▆▆▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>2.77061</td></tr><tr><td>Train - top-1</td><td>0.43577</td></tr><tr><td>Train - top-10</td><td>0.72723</td></tr><tr><td>Train - top-5</td><td>0.64474</td></tr><tr><td>Validation - loss</td><td>2.83298</td></tr><tr><td>Validation - top-1</td><td>0.43049</td></tr><tr><td>Validation - top-10</td><td>0.72037</td></tr><tr><td>Validation - top-5</td><td>0.63608</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vocal-flower-47</strong> at: <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/li4aot6u' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/li4aot6u</a><br/>Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230411_085603-li4aot6u/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GRU"
      ],
      "metadata": {
        "id": "Vq4L07Mq2eXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU\n",
        "!wandb online\n",
        "with wandb.init(\n",
        "        config=config,\n",
        "        project='INF8225 - TP3',  # Title of your project\n",
        "\n",
        "        group='Transformer - small',  # In what group of runs do you want this run to be in?\n",
        "        save_code=True,\n",
        "\n",
        "    ):\n",
        "  for batchsize in [64,128,256]:\n",
        "    print('batch size',batchsize)\n",
        "    config['batch_size'] = batchsize\n",
        "    train_model(model, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "45ae603c1c0b48c696996ebd5b16b30e",
            "f87031c6211444ba99d337de641d38fa",
            "dffea1f574424d73a263bd0d58b84c5e",
            "f14ab27287084163b6a28afcf3d077e1",
            "c9516c9fd975495e9b48034e1698489e",
            "55ac406f9088453db82f1ce5f742eace",
            "becba8d4ae2340d483e81ed1cf9bfd8f",
            "61bccaa2190c409d9ed76907ec5b7813"
          ]
        },
        "id": "cGlKW3R8HG_w",
        "outputId": "92726e3a-a052-4e2d-c1dc-8e17ecd081d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W&B online. Running your script from this directory will now sync to the cloud.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230411_070258-66ip2l1b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/66ip2l1b' target=\"_blank\">jolly-grass-44</a></strong> to <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/66ip2l1b' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/66ip2l1b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch size 64\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.38     top-1: 0.55    top-5: 0.74    top-10: 0.79\n",
            "Eval -    loss: 2.28     top-1: 0.56    top-5: 0.74    top-10: 0.79\n",
            "They manage to get along without much money.\n",
            "Ils ont l'intention de rester plus de temps.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.89     top-1: 0.62    top-5: 0.80    top-10: 0.85\n",
            "Eval -    loss: 1.81     top-1: 0.63    top-5: 0.81    top-10: 0.85\n",
            "Don't speak so fast, please.\n",
            "Ne parle pas si vite, s'il te plait.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.64     top-1: 0.66    top-5: 0.84    top-10: 0.88\n",
            "Eval -    loss: 1.59     top-1: 0.66    top-5: 0.84    top-10: 0.88\n",
            "Stop treating me like a child.\n",
            "Arrête de me mettre comme un enfant.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.46     top-1: 0.69    top-5: 0.86    top-10: 0.90\n",
            "Eval -    loss: 1.47     top-1: 0.68    top-5: 0.86    top-10: 0.89\n",
            "You're worried, aren't you?\n",
            "Tu es inquiète, n'est-ce pas ?\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.34     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "Eval -    loss: 1.40     top-1: 0.69    top-5: 0.87    top-10: 0.90\n",
            "Is there a school bus?\n",
            "Y a-t-il un école en Australie ?\n",
            "batch size 128\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 1.25     top-1: 0.71    top-5: 0.89    top-10: 0.92\n",
            "Eval -    loss: 1.36     top-1: 0.70    top-5: 0.87    top-10: 0.91\n",
            "These pants fit me well.\n",
            "Ces remarques me vont bien bien.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.19     top-1: 0.73    top-5: 0.90    top-10: 0.93\n",
            "Eval -    loss: 1.32     top-1: 0.71    top-5: 0.88    top-10: 0.91\n",
            "I've never been abroad.\n",
            "Je n'ai jamais été en retard à l'étranger.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.15     top-1: 0.73    top-5: 0.90    top-10: 0.93\n",
            "Eval -    loss: 1.30     top-1: 0.71    top-5: 0.88    top-10: 0.91\n",
            "Where shall we meet?\n",
            "Où pouvons-nous nous rencontrer ?\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.09     top-1: 0.74    top-5: 0.91    top-10: 0.94\n",
            "Eval -    loss: 1.29     top-1: 0.72    top-5: 0.88    top-10: 0.91\n",
            "I don't think that.\n",
            "Je ne le pense pas.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.06     top-1: 0.74    top-5: 0.91    top-10: 0.94\n",
            "Eval -    loss: 1.27     top-1: 0.72    top-5: 0.89    top-10: 0.92\n",
            "Let's see what happens.\n",
            "Voyons ce qui arrive ensuite.\n",
            "batch size 256\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 1.06     top-1: 0.75    top-5: 0.91    top-10: 0.94\n",
            "Eval -    loss: 1.27     top-1: 0.72    top-5: 0.89    top-10: 0.92\n",
            "I don't see anybody else around here.\n",
            "Je ne vois nulle part où aller par ici.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.00     top-1: 0.75    top-5: 0.92    top-10: 0.95\n",
            "Eval -    loss: 1.26     top-1: 0.72    top-5: 0.89    top-10: 0.92\n",
            "I will not allow you to use my pen.\n",
            "Je ne t'laisserai pas utiliser mon stylo.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 0.97     top-1: 0.76    top-5: 0.92    top-10: 0.95\n",
            "Eval -    loss: 1.26     top-1: 0.72    top-5: 0.89    top-10: 0.92\n",
            "It started raining just as I was leaving home.\n",
            "Il se mit à pleuvoir avant que j'y aille chez moi.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 0.96     top-1: 0.76    top-5: 0.92    top-10: 0.95\n",
            "Eval -    loss: 1.25     top-1: 0.73    top-5: 0.89    top-10: 0.92\n",
            "I felt very sad.\n",
            "Je me suis senti très triste.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 0.93     top-1: 0.77    top-5: 0.93    top-10: 0.95\n",
            "Eval -    loss: 1.26     top-1: 0.73    top-5: 0.89    top-10: 0.92\n",
            "I want you to tell me who did this.\n",
            "Je veux que tu me dises qui a fait ça.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.422 MB of 0.422 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45ae603c1c0b48c696996ebd5b16b30e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█▇███████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇█████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>Validation - loss</td><td>█▅▃▃▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation - top-1</td><td>▁▄▅▆▇▇▇▇███████</td></tr><tr><td>Validation - top-10</td><td>▁▄▆▆▇▇▇████████</td></tr><tr><td>Validation - top-5</td><td>▁▄▆▆▇▇▇████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>0.93259</td></tr><tr><td>Train - top-1</td><td>0.76646</td></tr><tr><td>Train - top-10</td><td>0.95095</td></tr><tr><td>Train - top-5</td><td>0.92587</td></tr><tr><td>Validation - loss</td><td>1.25586</td></tr><tr><td>Validation - top-1</td><td>0.72671</td></tr><tr><td>Validation - top-10</td><td>0.92006</td></tr><tr><td>Validation - top-5</td><td>0.89116</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">jolly-grass-44</strong> at: <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/66ip2l1b' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/66ip2l1b</a><br/>Synced 5 W&B file(s), 3 media file(s), 5 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230411_070258-66ip2l1b/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU\n",
        "!wandb online\n",
        "with wandb.init(\n",
        "        config=config,\n",
        "        project='INF8225 - TP3',  # Title of your project\n",
        "\n",
        "        group='Transformer - small',  # In what group of runs do you want this run to be in?\n",
        "        save_code=True,\n",
        "\n",
        "    ):\n",
        "  for nlayer in [2,4]:\n",
        "    print('n_layers',nlayer)\n",
        "    config['n_layers'] = nlayer\n",
        "    train_model(model, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "49adb6077a3e407fa7c37e2ee27a5b1d",
            "d36c679ce2de4b8699d15db3c78c6cee",
            "248c5a3860e445bdb8959fdbde3a0dd5",
            "aff17674c4d546d281c8da05c6d43f23",
            "f2865b24e0a84405bc24a7df0aa58048",
            "175e6dafa98f4f1eb92458b631d1cdfa",
            "265903c72dbe487e9198b57e2dc621d3",
            "0c9fe6d3d12849df8dfeebaa120364c0"
          ]
        },
        "id": "BIh0jJN_W1CI",
        "outputId": "7d40b7c5-b97e-4830-e2ac-47167eec4523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W&B online. Running your script from this directory will now sync to the cloud.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230411_080956-mdnlakh8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/mdnlakh8' target=\"_blank\">devout-fire-45</a></strong> to <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/mdnlakh8' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/mdnlakh8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_layers 2\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.38     top-1: 0.55    top-5: 0.74    top-10: 0.79\n",
            "Eval -    loss: 2.28     top-1: 0.56    top-5: 0.74    top-10: 0.79\n",
            "They manage to get along without much money.\n",
            "Ils ont l'intention de rester plus de temps.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.89     top-1: 0.62    top-5: 0.80    top-10: 0.85\n",
            "Eval -    loss: 1.81     top-1: 0.63    top-5: 0.81    top-10: 0.85\n",
            "Don't speak so fast, please.\n",
            "Ne parle pas si vite, s'il te plait.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.64     top-1: 0.66    top-5: 0.84    top-10: 0.88\n",
            "Eval -    loss: 1.59     top-1: 0.66    top-5: 0.84    top-10: 0.88\n",
            "Stop treating me like a child.\n",
            "Arrête de me mettre comme un enfant.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.46     top-1: 0.69    top-5: 0.86    top-10: 0.90\n",
            "Eval -    loss: 1.47     top-1: 0.68    top-5: 0.86    top-10: 0.89\n",
            "You're worried, aren't you?\n",
            "Tu es inquiète, n'est-ce pas ?\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.34     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "Eval -    loss: 1.40     top-1: 0.69    top-5: 0.87    top-10: 0.90\n",
            "Is there a school bus?\n",
            "Y a-t-il un école en Australie ?\n",
            "n_layers 4\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 1.25     top-1: 0.71    top-5: 0.89    top-10: 0.92\n",
            "Eval -    loss: 1.36     top-1: 0.70    top-5: 0.87    top-10: 0.91\n",
            "These pants fit me well.\n",
            "Ces remarques me vont bien bien.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.19     top-1: 0.73    top-5: 0.90    top-10: 0.93\n",
            "Eval -    loss: 1.32     top-1: 0.71    top-5: 0.88    top-10: 0.91\n",
            "I've never been abroad.\n",
            "Je n'ai jamais été en retard à l'étranger.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.15     top-1: 0.73    top-5: 0.90    top-10: 0.93\n",
            "Eval -    loss: 1.30     top-1: 0.71    top-5: 0.88    top-10: 0.91\n",
            "Where shall we meet?\n",
            "Où pouvons-nous nous rencontrer ?\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.09     top-1: 0.74    top-5: 0.91    top-10: 0.94\n",
            "Eval -    loss: 1.29     top-1: 0.72    top-5: 0.88    top-10: 0.91\n",
            "I don't think that.\n",
            "Je ne le pense pas.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.06     top-1: 0.74    top-5: 0.91    top-10: 0.94\n",
            "Eval -    loss: 1.27     top-1: 0.72    top-5: 0.89    top-10: 0.92\n",
            "Let's see what happens.\n",
            "Voyons ce qui arrive ensuite.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.440 MB of 0.440 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49adb6077a3e407fa7c37e2ee27a5b1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇████████████████</td></tr><tr><td>Validation - loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr><tr><td>Validation - top-1</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>Validation - top-10</td><td>▁▄▆▇▇▇████</td></tr><tr><td>Validation - top-5</td><td>▁▄▆▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.06321</td></tr><tr><td>Train - top-1</td><td>0.74494</td></tr><tr><td>Train - top-10</td><td>0.93866</td></tr><tr><td>Train - top-5</td><td>0.91248</td></tr><tr><td>Validation - loss</td><td>1.27395</td></tr><tr><td>Validation - top-1</td><td>0.71748</td></tr><tr><td>Validation - top-10</td><td>0.91613</td></tr><tr><td>Validation - top-5</td><td>0.88587</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">devout-fire-45</strong> at: <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/mdnlakh8' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/mdnlakh8</a><br/>Synced 5 W&B file(s), 2 media file(s), 4 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230411_080956-mdnlakh8/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU\n",
        "!wandb online\n",
        "with wandb.init(\n",
        "        config=config,\n",
        "        project='INF8225 - TP3',  # Title of your project\n",
        "\n",
        "        group='Transformer - small',  # In what group of runs do you want this run to be in?\n",
        "        save_code=True,\n",
        "\n",
        "    ):\n",
        "  for dimembedding in [100,400]:\n",
        "    print('dim_embedding',dimembedding)\n",
        "    config['dim_embedding'] = dimembedding\n",
        "    train_model(model, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "my9NxdAXiN37",
        "outputId": "b12bf50a-e5fd-4050-881c-d9ca54b54d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W&B online. Running your script from this directory will now sync to the cloud.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230411_092527-1ss38gve</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/1ss38gve' target=\"_blank\">comfy-sun-48</a></strong> to <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/1ss38gve' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/1ss38gve</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dim_embedding 100\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.38     top-1: 0.55    top-5: 0.74    top-10: 0.79\n",
            "Eval -    loss: 2.28     top-1: 0.56    top-5: 0.74    top-10: 0.79\n",
            "They manage to get along without much money.\n",
            "Ils ont l'intention de rester plus de temps.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.89     top-1: 0.62    top-5: 0.80    top-10: 0.85\n",
            "Eval -    loss: 1.81     top-1: 0.63    top-5: 0.81    top-10: 0.85\n",
            "Don't speak so fast, please.\n",
            "Ne parle pas si vite, s'il te plait.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.64     top-1: 0.66    top-5: 0.84    top-10: 0.88\n",
            "Eval -    loss: 1.59     top-1: 0.66    top-5: 0.84    top-10: 0.88\n",
            "Stop treating me like a child.\n",
            "Arrête de me mettre comme un enfant.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.46     top-1: 0.69    top-5: 0.86    top-10: 0.90\n",
            "Eval -    loss: 1.47     top-1: 0.68    top-5: 0.86    top-10: 0.89\n",
            "You're worried, aren't you?\n",
            "Tu es inquiète, n'est-ce pas ?\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.34     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "Eval -    loss: 1.40     top-1: 0.69    top-5: 0.87    top-10: 0.90\n",
            "Is there a school bus?\n",
            "Y a-t-il un école en Australie ?\n",
            "dim_embedding 400\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 1.25     top-1: 0.71    top-5: 0.89    top-10: 0.92\n",
            "Eval -    loss: 1.36     top-1: 0.70    top-5: 0.87    top-10: 0.91\n",
            "These pants fit me well.\n",
            "Ces remarques me vont bien bien.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.19     top-1: 0.73    top-5: 0.90    top-10: 0.93\n",
            "Eval -    loss: 1.32     top-1: 0.71    top-5: 0.88    top-10: 0.91\n",
            "I've never been abroad.\n",
            "Je n'ai jamais été en retard à l'étranger.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.15     top-1: 0.73    top-5: 0.90    top-10: 0.93\n",
            "Eval -    loss: 1.30     top-1: 0.71    top-5: 0.88    top-10: 0.91\n",
            "Where shall we meet?\n",
            "Où pouvons-nous nous rencontrer ?\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.09     top-1: 0.74    top-5: 0.91    top-10: 0.94\n",
            "Eval -    loss: 1.29     top-1: 0.72    top-5: 0.88    top-10: 0.91\n",
            "I don't think that.\n",
            "Je ne le pense pas.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.06     top-1: 0.74    top-5: 0.91    top-10: 0.94\n",
            "Eval -    loss: 1.27     top-1: 0.72    top-5: 0.89    top-10: 0.92\n",
            "Let's see what happens.\n",
            "Voyons ce qui arrive ensuite.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇████████████████</td></tr><tr><td>Validation - loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr><tr><td>Validation - top-1</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>Validation - top-10</td><td>▁▄▆▇▇▇████</td></tr><tr><td>Validation - top-5</td><td>▁▄▆▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.06321</td></tr><tr><td>Train - top-1</td><td>0.74494</td></tr><tr><td>Train - top-10</td><td>0.93866</td></tr><tr><td>Train - top-5</td><td>0.91248</td></tr><tr><td>Validation - loss</td><td>1.27395</td></tr><tr><td>Validation - top-1</td><td>0.71748</td></tr><tr><td>Validation - top-10</td><td>0.91613</td></tr><tr><td>Validation - top-5</td><td>0.88587</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">comfy-sun-48</strong> at: <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/1ss38gve' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/1ss38gve</a><br/>Synced 5 W&B file(s), 2 media file(s), 4 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230411_092527-1ss38gve/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JV-v0BQT-Wvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "S9H-zGd3i8FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model, the dataloaders, optimizer and the loss function\n",
        "# Log every hyperparameters and arguments into the config dictionnary\n",
        "\n",
        "config = {\n",
        "    # General parameters\n",
        "    'epochs': 5,\n",
        "    'batch_size': 128,\n",
        "    'lr': 1e-3,\n",
        "    'betas': (0.9, 0.99),\n",
        "    'clip': 5,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "\n",
        "    # Model parameters\n",
        "    'n_tokens_src': len(train_dataset.en_vocab),\n",
        "    'n_tokens_tgt': len(train_dataset.fr_vocab),\n",
        "    'n_heads': 4,\n",
        "    'dim_embedding': 196,\n",
        "    'dim_hidden': 256,\n",
        "    'n_layers': 3,\n",
        "    'dropout': 0.1,\n",
        "    'model_type': 'GRU',\n",
        "\n",
        "    # Others\n",
        "    'max_sequence_length': MAX_SEQ_LEN,\n",
        "    'min_token_freq': MIN_TOK_FREQ,\n",
        "    'src_vocab': train_dataset.en_vocab,\n",
        "    'tgt_vocab': train_dataset.fr_vocab,\n",
        "    'src_tokenizer': en_tokenizer,\n",
        "    'tgt_tokenizer': fr_tokenizer,\n",
        "    'src_pad_idx': train_dataset.en_vocab['<pad>'],\n",
        "    'tgt_pad_idx': train_dataset.fr_vocab['<pad>'],\n",
        "    'seed': 0,\n",
        "    'log_every': 50,  # Number of batches between each wandb logs\n",
        "}\n",
        "\n",
        "torch.manual_seed(config['seed'])\n",
        "\n",
        "config['train_loader'] = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "\n",
        "    collate_fn=lambda batch: generate_batch(batch, config['src_pad_idx'], config['tgt_pad_idx'])\n",
        ")\n",
        "\n",
        "config['val_loader'] = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "\n",
        "\n",
        "    collate_fn=lambda batch: generate_batch(batch, config['src_pad_idx'], config['tgt_pad_idx'])\n",
        ")\n",
        "\"\"\"\n",
        "model = TranslationRNN(\n",
        "    config['n_tokens_src'],\n",
        "    config['n_tokens_tgt'],\n",
        "    config['dim_embedding'],\n",
        "    config['dim_hidden'],\n",
        "    config['n_layers'],\n",
        "    config['dropout'],\n",
        "    config['src_pad_idx'],\n",
        "    config['tgt_pad_idx'],\n",
        "    config['model_type'],\n",
        ")\n",
        "\"\"\"\n",
        "model = TranslationTransformer(\n",
        "    config['n_tokens_src'],\n",
        "    config['n_tokens_tgt'],\n",
        "    config['n_heads'],\n",
        "    config['dim_embedding'],\n",
        "    config['dim_hidden'],\n",
        "    config['n_layers'],\n",
        "    config['dropout'],\n",
        "    config['src_pad_idx'],\n",
        "    config['tgt_pad_idx'],\n",
        ")\n",
        "\n",
        "\n",
        "config['optimizer'] = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=config['lr'],\n",
        "    betas=config['betas'],\n",
        ")\n",
        "\n",
        "weight_classes = torch.ones(config['n_tokens_tgt'], dtype=torch.float)\n",
        "weight_classes[config['tgt_vocab']['<unk>']] = 0.1  # Lower the importance of that class\n",
        "config['loss'] = nn.CrossEntropyLoss(\n",
        "    weight=weight_classes,\n",
        "    ignore_index=config['tgt_pad_idx'],  # We do not have to learn those\n",
        ")\n",
        "\n",
        "summary(\n",
        "    model,\n",
        "    input_size=[\n",
        "        (config['batch_size'], config['max_sequence_length']),\n",
        "        (config['batch_size'], config['max_sequence_length'])\n",
        "    ],\n",
        "    dtypes=[torch.long, torch.long],\n",
        "    depth=3,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEUrc5U6i9uv",
        "outputId": "34faf0d7-00e9-4c39-be50-6f53e07a19bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "Layer (type:depth-idx)                             Output Shape              Param #\n",
              "====================================================================================================\n",
              "TranslationTransformer                             [128, 60, 17820]          --\n",
              "├─Embedding: 1-1                                   [128, 60, 196]            2,303,588\n",
              "├─Embedding: 1-2                                   [128, 60, 196]            38,416\n",
              "├─Dropout: 1-3                                     [128, 60, 196]            --\n",
              "├─Embedding: 1-4                                   [128, 60, 196]            3,492,720\n",
              "├─Embedding: 1-5                                   [128, 60, 196]            (recursive)\n",
              "├─Dropout: 1-6                                     [128, 60, 196]            --\n",
              "├─Transformer: 1-7                                 [128, 60, 196]            --\n",
              "│    └─TransformerEncoder: 2-1                     [128, 60, 196]            --\n",
              "│    │    └─ModuleList: 3-1                        --                        768,108\n",
              "│    └─TransformerDecoder: 2-2                     [128, 60, 196]            --\n",
              "│    │    └─ModuleList: 3-2                        --                        1,232,628\n",
              "├─Linear: 1-8                                      [128, 60, 17820]          3,510,540\n",
              "====================================================================================================\n",
              "Total params: 11,346,000\n",
              "Trainable params: 11,346,000\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 1.46\n",
              "====================================================================================================\n",
              "Input size (MB): 0.12\n",
              "Forward/backward pass size (MB): 1923.81\n",
              "Params size (MB): 45.38\n",
              "Estimated Total Size (MB): 1969.32\n",
              "===================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transformer\n"
      ],
      "metadata": {
        "id": "NA1PREl30IRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tranasformer\n",
        "!wandb online\n",
        "with wandb.init(\n",
        "        config=config,\n",
        "        project='INF8225 - TP3',  # Title of your project\n",
        "\n",
        "        group='Transformer - small',  # In what group of runs do you want this run to be in?\n",
        "        save_code=True,\n",
        "\n",
        "    ):\n",
        "  for batchsize in [64,256]:\n",
        "    print('batch size',batchsize)\n",
        "    config['batch_size'] = batchsize\n",
        "    train_model(model, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b25a3c761fcb4d1f8ba366b28d102ad3",
            "5d60e3f020e34e4cb830b76e5187f554",
            "cf6f25a116854b63bc3dc0ca85d577e4",
            "3b05e6dbf65744bbb3443133856a9eb3",
            "93ca628028f049019fc14fe98822ee56",
            "01d5952237bf4431b42e3f4cadbdc679",
            "5b0bdbba9c724933a4c7c59f4f43114d",
            "0f6cd6b56897414e9caffd46ece1121a"
          ]
        },
        "id": "qN6bB1JLj21U",
        "outputId": "ab4f6675-e13b-496c-b649-9834ff44b094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W&B online. Running your script from this directory will now sync to the cloud.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230411_103108-zxks6ree</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/zxks6ree' target=\"_blank\">proud-frost-50</a></strong> to <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/zxks6ree' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/zxks6ree</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch size 64\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 1.05     top-1: 0.75    top-5: 0.92    top-10: 0.94\n",
            "Eval -    loss: 1.00     top-1: 0.77    top-5: 0.92    top-10: 0.94\n",
            "Billie Holliday had an earthy, gravelly voice.\n",
            "Le <unk> a eu une voix <unk>.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 0.99     top-1: 0.76    top-5: 0.93    top-10: 0.95\n",
            "Eval -    loss: 0.98     top-1: 0.77    top-5: 0.93    top-10: 0.95\n",
            "Don't just stand there, say something.\n",
            "Ne restez pas planté là-bas, dis quelque chose.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 0.97     top-1: 0.77    top-5: 0.93    top-10: 0.95\n",
            "Eval -    loss: 0.95     top-1: 0.77    top-5: 0.93    top-10: 0.95\n",
            "I was really quite stiff.\n",
            "J'étais vraiment tout à fait mal.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 0.93     top-1: 0.78    top-5: 0.93    top-10: 0.95\n",
            "Eval -    loss: 0.93     top-1: 0.78    top-5: 0.93    top-10: 0.95\n",
            "I was a fool to trust you.\n",
            "J'ai été idiot de te faire confiance.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 0.89     top-1: 0.78    top-5: 0.94    top-10: 0.96\n",
            "Eval -    loss: 0.93     top-1: 0.78    top-5: 0.93    top-10: 0.95\n",
            "I don't play chess as often as I used to.\n",
            "Je ne joue pas aux échecs aussi souvent qu'avant.\n",
            "batch size 256\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 0.86     top-1: 0.78    top-5: 0.94    top-10: 0.96\n",
            "Eval -    loss: 0.92     top-1: 0.78    top-5: 0.93    top-10: 0.95\n",
            "You look like you're enjoying yourself.\n",
            "Vous avez l'air de vous amuser.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 0.85     top-1: 0.79    top-5: 0.94    top-10: 0.96\n",
            "Eval -    loss: 0.91     top-1: 0.79    top-5: 0.93    top-10: 0.95\n",
            "The elevator is out of order.\n",
            "L'ascenseur est en panne.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 0.83     top-1: 0.79    top-5: 0.94    top-10: 0.96\n",
            "Eval -    loss: 0.90     top-1: 0.79    top-5: 0.93    top-10: 0.95\n",
            "He's nothing more than a common thug.\n",
            "Il n'est rien de plus qu'un commun commun.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 0.81     top-1: 0.79    top-5: 0.94    top-10: 0.96\n",
            "Eval -    loss: 0.90     top-1: 0.79    top-5: 0.94    top-10: 0.96\n",
            "You won't be fired.\n",
            "Vous ne serez pas viré.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 0.83     top-1: 0.79    top-5: 0.94    top-10: 0.96\n",
            "Eval -    loss: 0.88     top-1: 0.79    top-5: 0.94    top-10: 0.96\n",
            "I'll miss you very much if you go.\n",
            "Tu vas beaucoup me manquer.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.369 MB of 0.369 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b25a3c761fcb4d1f8ba366b28d102ad3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>▇███▅▆▇▇▄▆▆▆▄▅▆▅▃▄▅▅▃▄▅▅▂▃▄▄▂▃▄▄▁▂▃▄▁▂▃▄</td></tr><tr><td>Train - top-1</td><td>▂▂▁▂▄▂▂▂▅▄▃▄▅▄▄▄▆▅▅▅▆▅▅▅▇▆▅▅█▆▆▅▇▇▆▆█▇▆▆</td></tr><tr><td>Train - top-10</td><td>▂▁▁▁▄▃▂▁▅▃▃▃▅▅▃▄▆▅▄▄▆▅▄▄▇▆▅▅▇▆▅▅▇▇▆▅█▇▆▅</td></tr><tr><td>Train - top-5</td><td>▂▁▁▁▄▃▂▂▅▃▃▃▅▄▃▃▆▅▄▄▆▅▄▄▇▆▅▅▇▆▅▅▇▇▆▆█▇▆▅</td></tr><tr><td>Validation - loss</td><td>█▇▅▄▄▃▂▂▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▂▃▅▅▆▇█▇█</td></tr><tr><td>Validation - top-10</td><td>▁▃▄▅▅▆▇▇▇█</td></tr><tr><td>Validation - top-5</td><td>▁▃▄▅▅▆▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>0.82515</td></tr><tr><td>Train - top-1</td><td>0.78987</td></tr><tr><td>Train - top-10</td><td>0.96311</td></tr><tr><td>Train - top-5</td><td>0.94358</td></tr><tr><td>Validation - loss</td><td>0.8845</td></tr><tr><td>Validation - top-1</td><td>0.78985</td></tr><tr><td>Validation - top-10</td><td>0.95616</td></tr><tr><td>Validation - top-5</td><td>0.93697</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">proud-frost-50</strong> at: <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/zxks6ree' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/zxks6ree</a><br/>Synced 5 W&B file(s), 2 media file(s), 4 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230411_103108-zxks6ree/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformer\n",
        "!wandb online\n",
        "with wandb.init(\n",
        "        config=config,\n",
        "        project='INF8225 - TP3',  # Title of your project\n",
        "\n",
        "        group='Transformer - small',  # In what group of runs do you want this run to be in?\n",
        "        save_code=True,\n",
        "\n",
        "    ):\n",
        "  for nlayer in [2,4]:\n",
        "    print('n_layers',nlayer)\n",
        "    config['n_layers'] = nlayer\n",
        "    train_model(model, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ANoIp0F_3oWB",
        "outputId": "c3b6616b-eda1-4895-f2df-831c09d631cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W&B online. Running your script from this directory will now sync to the cloud.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230411_104825-9a35k3kf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/9a35k3kf' target=\"_blank\">devout-blaze-51</a></strong> to <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/9a35k3kf' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/9a35k3kf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_layers 2\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 1.77     top-1: 0.65    top-5: 0.84    top-10: 0.87\n",
            "Eval -    loss: 1.56     top-1: 0.67    top-5: 0.86    top-10: 0.89\n",
            "I didn't know what time I was supposed to leave.\n",
            "Je ne savais pas ce que j'étais censé partir.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.41     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "Eval -    loss: 1.27     top-1: 0.72    top-5: 0.89    top-10: 0.92\n",
            "We appreciate the advice.\n",
            "Nous apprécions les conseils.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.24     top-1: 0.72    top-5: 0.90    top-10: 0.93\n",
            "Eval -    loss: 1.15     top-1: 0.74    top-5: 0.90    top-10: 0.93\n",
            "I've already paid you.\n",
            "Je t'ai déjà payé.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.14     top-1: 0.74    top-5: 0.91    top-10: 0.94\n",
            "Eval -    loss: 1.08     top-1: 0.75    top-5: 0.91    top-10: 0.94\n",
            "You don't seem to understand.\n",
            "Vous ne semblez pas comprendre.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.11     top-1: 0.75    top-5: 0.91    top-10: 0.94\n",
            "Eval -    loss: 1.04     top-1: 0.76    top-5: 0.92    top-10: 0.94\n",
            "I recovered.\n",
            "Je me suis rétabli.\n",
            "n_layers 4\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 1.05     top-1: 0.75    top-5: 0.92    top-10: 0.94\n",
            "Eval -    loss: 1.00     top-1: 0.77    top-5: 0.92    top-10: 0.94\n",
            "Billie Holliday had an earthy, gravelly voice.\n",
            "Le <unk> a eu une voix <unk>.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 0.99     top-1: 0.76    top-5: 0.93    top-10: 0.95\n",
            "Eval -    loss: 0.98     top-1: 0.77    top-5: 0.93    top-10: 0.95\n",
            "Don't just stand there, say something.\n",
            "Ne restez pas planté là-bas, dis quelque chose.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 0.97     top-1: 0.77    top-5: 0.93    top-10: 0.95\n",
            "Eval -    loss: 0.95     top-1: 0.77    top-5: 0.93    top-10: 0.95\n",
            "I was really quite stiff.\n",
            "J'étais vraiment tout à fait mal.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 0.93     top-1: 0.78    top-5: 0.93    top-10: 0.95\n",
            "Eval -    loss: 0.93     top-1: 0.78    top-5: 0.93    top-10: 0.95\n",
            "I was a fool to trust you.\n",
            "J'ai été idiot de te faire confiance.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 0.89     top-1: 0.78    top-5: 0.94    top-10: 0.96\n",
            "Eval -    loss: 0.93     top-1: 0.78    top-5: 0.93    top-10: 0.95\n",
            "I don't play chess as often as I used to.\n",
            "Je ne joue pas aux échecs aussi souvent qu'avant.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>Validation - loss</td><td>█▅▃▃▂▂▂▁▁▁</td></tr><tr><td>Validation - top-1</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>Validation - top-10</td><td>▁▄▆▆▇▇▇███</td></tr><tr><td>Validation - top-5</td><td>▁▄▆▆▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>0.88728</td></tr><tr><td>Train - top-1</td><td>0.78144</td></tr><tr><td>Train - top-10</td><td>0.95853</td></tr><tr><td>Train - top-5</td><td>0.93783</td></tr><tr><td>Validation - loss</td><td>0.92626</td></tr><tr><td>Validation - top-1</td><td>0.78063</td></tr><tr><td>Validation - top-10</td><td>0.95166</td></tr><tr><td>Validation - top-5</td><td>0.93126</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">devout-blaze-51</strong> at: <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/9a35k3kf' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/9a35k3kf</a><br/>Synced 5 W&B file(s), 2 media file(s), 4 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230411_104825-9a35k3kf/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformer\n",
        "!wandb online\n",
        "with wandb.init(\n",
        "        config=config,\n",
        "        project='INF8225 - TP3',  # Title of your project\n",
        "\n",
        "        group='Transformer - small',  # In what group of runs do you want this run to be in?\n",
        "        save_code=True,\n",
        "\n",
        "    ):\n",
        "  for dimembedding in [100,400]:\n",
        "    print('dim_embedding',dimembedding)\n",
        "    config['dim_embedding'] = dimembedding\n",
        "    train_model(model, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2cf1b8688ec648c6a83bf24140748c1c",
            "ad6d91d94d36461390387b875a61b3b3",
            "2e114b6fbc7944e886c9fffeb9ae4436",
            "325aa0c20e2145a5adfc4c44d3020b8d",
            "2c566246d3b24722898002224ccdb54f",
            "553c1aa57f7f40e79e544f98af5b4030",
            "a8a018261c55425eb12bb5845e677675",
            "ab10ee588fdc4218842402fd5b6545ce"
          ]
        },
        "id": "km-mMEk332oG",
        "outputId": "67290ee0-4450-4d92-c82b-225dbc99e17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W&B online. Running your script from this directory will now sync to the cloud.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230411_110133-hner0gd0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/hner0gd0' target=\"_blank\">earthy-meadow-52</a></strong> to <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/hner0gd0' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/hner0gd0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dim_embedding 100\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 1.77     top-1: 0.65    top-5: 0.84    top-10: 0.87\n",
            "Eval -    loss: 1.56     top-1: 0.67    top-5: 0.86    top-10: 0.89\n",
            "I didn't know what time I was supposed to leave.\n",
            "Je ne savais pas ce que j'étais censé partir.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.41     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "Eval -    loss: 1.27     top-1: 0.72    top-5: 0.89    top-10: 0.92\n",
            "We appreciate the advice.\n",
            "Nous apprécions les conseils.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.24     top-1: 0.72    top-5: 0.90    top-10: 0.93\n",
            "Eval -    loss: 1.15     top-1: 0.74    top-5: 0.90    top-10: 0.93\n",
            "I've already paid you.\n",
            "Je t'ai déjà payé.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.14     top-1: 0.74    top-5: 0.91    top-10: 0.94\n",
            "Eval -    loss: 1.08     top-1: 0.75    top-5: 0.91    top-10: 0.94\n",
            "You don't seem to understand.\n",
            "Vous ne semblez pas comprendre.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.11     top-1: 0.75    top-5: 0.91    top-10: 0.94\n",
            "Eval -    loss: 1.04     top-1: 0.76    top-5: 0.92    top-10: 0.94\n",
            "I recovered.\n",
            "Je me suis rétabli.\n",
            "dim_embedding 400\n",
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 1.05     top-1: 0.75    top-5: 0.92    top-10: 0.94\n",
            "Eval -    loss: 1.00     top-1: 0.77    top-5: 0.92    top-10: 0.94\n",
            "Billie Holliday had an earthy, gravelly voice.\n",
            "Le <unk> a eu une voix <unk>.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 0.99     top-1: 0.76    top-5: 0.93    top-10: 0.95\n",
            "Eval -    loss: 0.98     top-1: 0.77    top-5: 0.93    top-10: 0.95\n",
            "Don't just stand there, say something.\n",
            "Ne restez pas planté là-bas, dis quelque chose.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 0.97     top-1: 0.77    top-5: 0.93    top-10: 0.95\n",
            "Eval -    loss: 0.95     top-1: 0.77    top-5: 0.93    top-10: 0.95\n",
            "I was really quite stiff.\n",
            "J'étais vraiment tout à fait mal.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 0.93     top-1: 0.78    top-5: 0.93    top-10: 0.95\n",
            "Eval -    loss: 0.93     top-1: 0.78    top-5: 0.93    top-10: 0.95\n",
            "I was a fool to trust you.\n",
            "J'ai été idiot de te faire confiance.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 0.89     top-1: 0.78    top-5: 0.94    top-10: 0.96\n",
            "Eval -    loss: 0.93     top-1: 0.78    top-5: 0.93    top-10: 0.95\n",
            "I don't play chess as often as I used to.\n",
            "Je ne joue pas aux échecs aussi souvent qu'avant.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.402 MB of 0.402 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cf1b8688ec648c6a83bf24140748c1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>Validation - loss</td><td>█▅▃▃▂▂▂▁▁▁</td></tr><tr><td>Validation - top-1</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>Validation - top-10</td><td>▁▄▆▆▇▇▇███</td></tr><tr><td>Validation - top-5</td><td>▁▄▆▆▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>0.88728</td></tr><tr><td>Train - top-1</td><td>0.78144</td></tr><tr><td>Train - top-10</td><td>0.95853</td></tr><tr><td>Train - top-5</td><td>0.93783</td></tr><tr><td>Validation - loss</td><td>0.92626</td></tr><tr><td>Validation - top-1</td><td>0.78063</td></tr><tr><td>Validation - top-10</td><td>0.95166</td></tr><tr><td>Validation - top-5</td><td>0.93126</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">earthy-meadow-52</strong> at: <a href='https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/hner0gd0' target=\"_blank\">https://wandb.ai/team-amine/INF8225%20-%20TP3/runs/hner0gd0</a><br/>Synced 5 W&B file(s), 2 media file(s), 4 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230411_110133-hner0gd0/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuClass": "premium"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7acfdb23d5394f4bb12201d64f2b48a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00908a8b80564b5f8991b07f08f7541e",
              "IPY_MODEL_19994336463f44a2aa6d17c48833592b"
            ],
            "layout": "IPY_MODEL_bb42ac1cdc134d5da2adf56bb46ad99d"
          }
        },
        "00908a8b80564b5f8991b07f08f7541e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34cfbe39a7804a94ac64f732c57ce043",
            "placeholder": "​",
            "style": "IPY_MODEL_ed7856247c7c41bd94c6a68801a71800",
            "value": "0.365 MB of 0.519 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "19994336463f44a2aa6d17c48833592b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_312fc6cf4ad94fb7ae2b8b47d2b164bc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0ae3b31fd054c7d9ee1f86058b3e32e",
            "value": 0.703777394476788
          }
        },
        "bb42ac1cdc134d5da2adf56bb46ad99d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34cfbe39a7804a94ac64f732c57ce043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed7856247c7c41bd94c6a68801a71800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "312fc6cf4ad94fb7ae2b8b47d2b164bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0ae3b31fd054c7d9ee1f86058b3e32e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f9b12c56ad94315b326e39a0497c2f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e146415ca7054d758ef277951645dbd9",
              "IPY_MODEL_00837fb64644444fa57a62f2ce48a20f"
            ],
            "layout": "IPY_MODEL_933fde9f7c8a48dc88d2cf4e8d0c96fe"
          }
        },
        "e146415ca7054d758ef277951645dbd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b3011330b0646a3ab0612dd0f51e3c5",
            "placeholder": "​",
            "style": "IPY_MODEL_de659010b610450084257fcf6dcc5fb5",
            "value": "0.369 MB of 0.461 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "00837fb64644444fa57a62f2ce48a20f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b0e7d7f0202417bbe8607d7a4ed4151",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6cc01f7dfd2b4bfa907ff71cc27e1f2d",
            "value": 0.7994411917382411
          }
        },
        "933fde9f7c8a48dc88d2cf4e8d0c96fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b3011330b0646a3ab0612dd0f51e3c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de659010b610450084257fcf6dcc5fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b0e7d7f0202417bbe8607d7a4ed4151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cc01f7dfd2b4bfa907ff71cc27e1f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70a7bc0dbf0940deb08c3465140fcfb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85960e44b13e4c35990ff24555b643f9",
              "IPY_MODEL_eef67b9fa4cb4c1bb2ebe49f2095949e"
            ],
            "layout": "IPY_MODEL_4c8ac17e808d4e658e91353ff7c69033"
          }
        },
        "85960e44b13e4c35990ff24555b643f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_205908a94f8842d28d22e7f8380f8353",
            "placeholder": "​",
            "style": "IPY_MODEL_58d6e5366601491aa08bcb51de5d9a8a",
            "value": "1.318 MB of 1.318 MB uploaded (0.109 MB deduped)\r"
          }
        },
        "eef67b9fa4cb4c1bb2ebe49f2095949e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1b0c6cadba944e394f1a0f8127d18af",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39c7eecd6e2c4bd3868dc2b58921ffad",
            "value": 1
          }
        },
        "4c8ac17e808d4e658e91353ff7c69033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "205908a94f8842d28d22e7f8380f8353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58d6e5366601491aa08bcb51de5d9a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1b0c6cadba944e394f1a0f8127d18af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39c7eecd6e2c4bd3868dc2b58921ffad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "832b7977e98148c18d38e000e4caa381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea030a276f404323adbe6868297018ef",
              "IPY_MODEL_6d7e84ef033f4042ac7130010077c50b"
            ],
            "layout": "IPY_MODEL_eab5ac9fc1a04e29bf9f732b02fafd8f"
          }
        },
        "ea030a276f404323adbe6868297018ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f09a51cac7e346d9bc2dec7efaef2b72",
            "placeholder": "​",
            "style": "IPY_MODEL_a575bc47b3a74c12bcd4fbee2444324e",
            "value": "0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "6d7e84ef033f4042ac7130010077c50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b199ae94b2a4728b0fa5339a742639b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b5d8a83db394269b360e71cad0725bc",
            "value": 1
          }
        },
        "eab5ac9fc1a04e29bf9f732b02fafd8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f09a51cac7e346d9bc2dec7efaef2b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a575bc47b3a74c12bcd4fbee2444324e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b199ae94b2a4728b0fa5339a742639b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b5d8a83db394269b360e71cad0725bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45ae603c1c0b48c696996ebd5b16b30e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f87031c6211444ba99d337de641d38fa",
              "IPY_MODEL_dffea1f574424d73a263bd0d58b84c5e"
            ],
            "layout": "IPY_MODEL_f14ab27287084163b6a28afcf3d077e1"
          }
        },
        "f87031c6211444ba99d337de641d38fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9516c9fd975495e9b48034e1698489e",
            "placeholder": "​",
            "style": "IPY_MODEL_55ac406f9088453db82f1ce5f742eace",
            "value": "0.422 MB of 0.422 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "dffea1f574424d73a263bd0d58b84c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_becba8d4ae2340d483e81ed1cf9bfd8f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61bccaa2190c409d9ed76907ec5b7813",
            "value": 1
          }
        },
        "f14ab27287084163b6a28afcf3d077e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9516c9fd975495e9b48034e1698489e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55ac406f9088453db82f1ce5f742eace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "becba8d4ae2340d483e81ed1cf9bfd8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61bccaa2190c409d9ed76907ec5b7813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49adb6077a3e407fa7c37e2ee27a5b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d36c679ce2de4b8699d15db3c78c6cee",
              "IPY_MODEL_248c5a3860e445bdb8959fdbde3a0dd5"
            ],
            "layout": "IPY_MODEL_aff17674c4d546d281c8da05c6d43f23"
          }
        },
        "d36c679ce2de4b8699d15db3c78c6cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2865b24e0a84405bc24a7df0aa58048",
            "placeholder": "​",
            "style": "IPY_MODEL_175e6dafa98f4f1eb92458b631d1cdfa",
            "value": "0.561 MB of 0.561 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "248c5a3860e445bdb8959fdbde3a0dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_265903c72dbe487e9198b57e2dc621d3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c9fe6d3d12849df8dfeebaa120364c0",
            "value": 1
          }
        },
        "aff17674c4d546d281c8da05c6d43f23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2865b24e0a84405bc24a7df0aa58048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "175e6dafa98f4f1eb92458b631d1cdfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "265903c72dbe487e9198b57e2dc621d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c9fe6d3d12849df8dfeebaa120364c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b25a3c761fcb4d1f8ba366b28d102ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d60e3f020e34e4cb830b76e5187f554",
              "IPY_MODEL_cf6f25a116854b63bc3dc0ca85d577e4"
            ],
            "layout": "IPY_MODEL_3b05e6dbf65744bbb3443133856a9eb3"
          }
        },
        "5d60e3f020e34e4cb830b76e5187f554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93ca628028f049019fc14fe98822ee56",
            "placeholder": "​",
            "style": "IPY_MODEL_01d5952237bf4431b42e3f4cadbdc679",
            "value": "0.369 MB of 0.369 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "cf6f25a116854b63bc3dc0ca85d577e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b0bdbba9c724933a4c7c59f4f43114d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f6cd6b56897414e9caffd46ece1121a",
            "value": 1
          }
        },
        "3b05e6dbf65744bbb3443133856a9eb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93ca628028f049019fc14fe98822ee56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01d5952237bf4431b42e3f4cadbdc679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b0bdbba9c724933a4c7c59f4f43114d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f6cd6b56897414e9caffd46ece1121a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cf1b8688ec648c6a83bf24140748c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad6d91d94d36461390387b875a61b3b3",
              "IPY_MODEL_2e114b6fbc7944e886c9fffeb9ae4436"
            ],
            "layout": "IPY_MODEL_325aa0c20e2145a5adfc4c44d3020b8d"
          }
        },
        "ad6d91d94d36461390387b875a61b3b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c566246d3b24722898002224ccdb54f",
            "placeholder": "​",
            "style": "IPY_MODEL_553c1aa57f7f40e79e544f98af5b4030",
            "value": "0.402 MB of 0.402 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "2e114b6fbc7944e886c9fffeb9ae4436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8a018261c55425eb12bb5845e677675",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab10ee588fdc4218842402fd5b6545ce",
            "value": 1
          }
        },
        "325aa0c20e2145a5adfc4c44d3020b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c566246d3b24722898002224ccdb54f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "553c1aa57f7f40e79e544f98af5b4030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8a018261c55425eb12bb5845e677675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab10ee588fdc4218842402fd5b6545ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}